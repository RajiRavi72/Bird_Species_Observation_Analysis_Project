{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afb1551",
   "metadata": {},
   "source": [
    "Read the excel file Bird_Monitoring_Data_FOREST.XLSX with all the sheets into a dict using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec119db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Specify the file path\n",
    "forest_file_path = \"Bird_Monitoring_Data_FOREST.XLSX\"\n",
    "\n",
    "# Read the Excel file with multiple sheets\n",
    "forest_excel_data = pd.ExcelFile(forest_file_path)\n",
    "\n",
    "# Get all sheet names\n",
    "forest_sheet_names = forest_excel_data.sheet_names\n",
    "\n",
    "# Read data from all sheets into a dictionary\n",
    "forest_sheets_dict = {sheet: forest_excel_data.parse(sheet) for sheet in forest_sheet_names}\n",
    "forest_sheets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6bff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ANTI', 'CATO', 'CHOH', 'GWMP', 'HAFE', 'MANA', 'MONO', 'NACE', 'PRWI', 'ROCR', 'WOTR'])\n"
     ]
    }
   ],
   "source": [
    "print(forest_sheets_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa28f1",
   "metadata": {},
   "source": [
    "Now to check if all Forest Sheets have same columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3efba28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sheets have same columns\n"
     ]
    }
   ],
   "source": [
    "# Get list of all DataFrames\n",
    "dataframes = list(forest_sheets_dict.values())\n",
    "# Get column names of the first sheet\n",
    "first_columns = dataframes[0].columns\n",
    "\n",
    "# Check all others against the first\n",
    "all_same = all(df.columns.equals(first_columns) for df in dataframes)\n",
    "\n",
    "print(\"All sheets have same columns\" if all_same else \"Sheets have different columns.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a5e73f",
   "metadata": {},
   "source": [
    "We can now merge the sheets dataframes to a single dataframe called forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f0f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8546, 29)\n"
     ]
    }
   ],
   "source": [
    "forest_merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "print(forest_merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367b196",
   "metadata": {},
   "source": [
    "Now we get the raw data for Bird_Monitoring_Data_GRASSLAND.XLSX and read all sheets into a dict using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Specify the file path\n",
    "grassland_file_path = \"Bird_Monitoring_Data_GRASSLAND.XLSX\"\n",
    "\n",
    "# Read the Excel file with multiple sheets\n",
    "grassland_excel_data = pd.ExcelFile(grassland_file_path)\n",
    "\n",
    "# Get all sheet names\n",
    "grassland_sheet_names = grassland_excel_data.sheet_names\n",
    "\n",
    "# Read data from all sheets into a dictionary\n",
    "grassland_sheets_dict = {sheet: grassland_excel_data.parse(sheet) for sheet in grassland_sheet_names}\n",
    "grassland_sheets_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261c89f",
   "metadata": {},
   "source": [
    "Now we get the Sheets names from the grassland_dict key values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d07457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ANTI', 'HAFE', 'MANA', 'MONO'])\n"
     ]
    }
   ],
   "source": [
    "print(grassland_sheets_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31eb7bc",
   "metadata": {},
   "source": [
    "Now to check if all Grassland Sheets have same columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63be8d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sheets have same columns\n"
     ]
    }
   ],
   "source": [
    "# Get list of all DataFrames\n",
    "dataframes = list(grassland_sheets_dict.values())\n",
    "# Get column names of the first sheet\n",
    "first_columns = dataframes[0].columns\n",
    "\n",
    "# Check all others against the first\n",
    "all_same = all(df.columns.equals(first_columns) for df in dataframes)\n",
    "\n",
    "print(\"All sheets have same columns\" if all_same else \"Sheets have different columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d53fe5",
   "metadata": {},
   "source": [
    "We can now merge the sheets dataframes to a single dataframe called grassland_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d115051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8531, 29)\n"
     ]
    }
   ],
   "source": [
    "grassland_merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "print(grassland_merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc69ff",
   "metadata": {},
   "source": [
    "The grassland_merged_df has 8531 rows and 29 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b3f0f",
   "metadata": {},
   "source": [
    "Now we can see if we can merge forest df and grassland df into a single merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d4dda66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot merge: Columns are not the same.\n",
      "forest_merged_df columns: ['Admin_Unit_Code', 'Sub_Unit_Code', 'Site_Name', 'Plot_Name', 'Location_Type', 'Year', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit', 'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex', 'Common_Name', 'Scientific_Name', 'AcceptedTSN', 'NPSTaxonCode', 'AOU_Code', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status', 'Temperature', 'Humidity', 'Sky', 'Wind', 'Disturbance', 'Initial_Three_Min_Cnt']\n",
      "grassland_merged_df columns: ['Admin_Unit_Code', 'Sub_Unit_Code', 'Plot_Name', 'Location_Type', 'Year', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit', 'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex', 'Common_Name', 'Scientific_Name', 'AcceptedTSN', 'TaxonCode', 'AOU_Code', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status', 'Temperature', 'Humidity', 'Sky', 'Wind', 'Disturbance', 'Previously_Obs', 'Initial_Three_Min_Cnt']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Check if columns are the same\n",
    "if forest_merged_df.columns.equals(grassland_merged_df.columns):\n",
    "    # Step 2: Merge the DataFrames\n",
    "    merged_df = pd.concat([forest_merged_df, grassland_merged_df], ignore_index=True)\n",
    "    print(\"Successfully merged. Shape of merged_df:\", merged_df.shape)\n",
    "else:\n",
    "    print(\"Cannot merge: Columns are not the same.\")\n",
    "    print(\"forest_merged_df columns:\", list(forest_merged_df.columns))\n",
    "    print(\"grassland_merged_df columns:\", list(grassland_merged_df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12fa911",
   "metadata": {},
   "source": [
    "To find which columns are different in forest and grassland dfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "088157d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in forest_merged_df: {'NPSTaxonCode', 'Site_Name'}\n",
      "Only in grassland_merged_df: {'TaxonCode', 'Previously_Obs'}\n"
     ]
    }
   ],
   "source": [
    "forest_cols = set(forest_merged_df.columns)\n",
    "grassland_cols = set(grassland_merged_df.columns)\n",
    "\n",
    "print(\"Only in forest_merged_df:\", forest_cols - grassland_cols)\n",
    "print(\"Only in grassland_merged_df:\", grassland_cols - forest_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51a738",
   "metadata": {},
   "source": [
    "FOREST DATA CLEANING AND PRE PROCESSING:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4b568",
   "metadata": {},
   "source": [
    "Now we find out which columns have nulls in forest df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "840a8d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sub_Unit_Code', 'ID_Method', 'Distance', 'Sex', 'AcceptedTSN']\n"
     ]
    }
   ],
   "source": [
    "null_columns = forest_merged_df.columns[forest_merged_df.isnull().any()].tolist()\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41e655",
   "metadata": {},
   "source": [
    "So there are nulls in the above 5 columns. To find the number of nulls in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9702524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub_Unit_Code    7824\n",
      "ID_Method           1\n",
      "Distance           92\n",
      "Sex              5183\n",
      "AcceptedTSN         9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List of target columns\n",
    "columns_to_check = ['Sub_Unit_Code', 'ID_Method', 'Distance', 'Sex', 'AcceptedTSN']\n",
    "\n",
    "# Count nulls in each column\n",
    "null_counts = forest_merged_df[columns_to_check].isnull().sum()\n",
    "\n",
    "print(null_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf3389",
   "metadata": {},
   "source": [
    "Get the Admin_Unit_Code where the Sub_Unit_Code is null in forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00fe9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admin_Unit_Code values where Sub_Unit_Code is null:\n",
      "['ANTI' 'CATO' 'CHOH' 'GWMP' 'HAFE' 'MANA' 'MONO' 'PRWI' 'ROCR' 'WOTR']\n"
     ]
    }
   ],
   "source": [
    "null_admin_units = forest_merged_df[forest_merged_df['Sub_Unit_Code'].isnull()]['Admin_Unit_Code'].unique()\n",
    "print(\"Admin_Unit_Code values where Sub_Unit_Code is null:\")\n",
    "print(null_admin_units)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783f5584",
   "metadata": {},
   "source": [
    "To get the list of Admin_Unit_Codes where the Sub_Unit_Code is not null in forest df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e875e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GWMP', 'THIS'), ('NACE', 'GREE'), ('NACE', 'PISC'), ('NACE', 'FOWA'), ('NACE', 'OXHI'), ('NACE', 'ANAC'), ('NACE', 'FOCI'), ('NACE', 'FODU')]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where Sub_Unit_Code is NOT null\n",
    "filtered_df = forest_merged_df[forest_merged_df['Sub_Unit_Code'].notnull()]\n",
    "\n",
    "# Get the unique pairs of Admin_Unit_Code and Sub_Unit_Code\n",
    "admin_subunit_pairs = filtered_df[['Admin_Unit_Code', 'Sub_Unit_Code']].drop_duplicates()\n",
    "\n",
    "# Optional: convert to list of tuples\n",
    "admin_subunit_list = list(admin_subunit_pairs.itertuples(index=False, name=None))\n",
    "\n",
    "# Print result\n",
    "print(admin_subunit_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e9caed",
   "metadata": {},
   "source": [
    "Since only Admin_Unit_Code 'NACE' has Sub_Unit_Code and only one row of Admin_Unit_Code GWMP has Sub_Unit_Code we can drop Sub_Unit_Code from the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "179a2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df.drop(columns=['Sub_Unit_Code'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc1107a",
   "metadata": {},
   "source": [
    "To print the single row where  'ID_Method' is null:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf449a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_null_id = forest_merged_df[forest_merged_df['ID_Method'].isnull()]\n",
    "print(rows_with_null_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0deff7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Singing' 'Calling' 'Visualization']\n"
     ]
    }
   ],
   "source": [
    "unique_id_methods = forest_merged_df['ID_Method'].dropna().unique()\n",
    "print(unique_id_methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9044fb24",
   "metadata": {},
   "source": [
    "To get the 'Common_Name' where the ID_Method is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94f5337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Red-eyed Vireo']\n"
     ]
    }
   ],
   "source": [
    "# Get Common_Name where ID_Method is null\n",
    "common_names_with_null_id_method = forest_merged_df.loc[forest_merged_df['ID_Method'].isnull(), 'Common_Name'].unique()\n",
    "\n",
    "print(common_names_with_null_id_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd9dd9",
   "metadata": {},
   "source": [
    "To fill the ID_Method which is null with the most frequent ID_Method for the same Common_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b895af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill null ID_Method with mode for each Common_Name group\n",
    "def fill_id_method_mode(group):\n",
    "    if group['ID_Method'].isnull().any():\n",
    "        mode_value = group['ID_Method'].mode()\n",
    "        if not mode_value.empty:\n",
    "            group['ID_Method'] = group['ID_Method'].fillna(mode_value[0])\n",
    "    return group\n",
    "\n",
    "# Apply the function grouped by Common_Name\n",
    "forest_merged_df = forest_merged_df.groupby('Common_Name', group_keys=False).apply(fill_id_method_mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa798888",
   "metadata": {},
   "source": [
    "To verify if the null value is filled with default and confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98d15633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(forest_merged_df['ID_Method'].isnull().sum())  # Should print 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6f195",
   "metadata": {},
   "source": [
    "To get the unique values of the column 'Sex' in forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de97209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Sex': ['Undetermined' 'Male']\n"
     ]
    }
   ],
   "source": [
    "unique_sex_values = forest_merged_df['Sex'].dropna().unique()\n",
    "print(\"Unique values in 'Sex':\", unique_sex_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002d752",
   "metadata": {},
   "source": [
    "Unique sex values already present are 'Undetermined'and 'Male'. So the nulls can be filled with 'Undetermined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c03abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df['Sex'] = forest_merged_df['Sex'].fillna('Undetermined')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007437c2",
   "metadata": {},
   "source": [
    "To check if nulls are changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "def05de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(forest_merged_df['Sex'].isnull().sum())   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f297854",
   "metadata": {},
   "source": [
    "To get the ID_Methods where Distance is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02fc8be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_Method values where Distance is null:\n",
      "['Visualization' 'Singing' 'Calling']\n"
     ]
    }
   ],
   "source": [
    "id_methods_with_null_distance = forest_merged_df[forest_merged_df['Distance'].isnull()]['ID_Method'].unique()\n",
    "print(\"ID_Method values where Distance is null:\")\n",
    "print(id_methods_with_null_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc335b",
   "metadata": {},
   "source": [
    "To get the Common_Name of the birds where Distance is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b048a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Common_Name Distance\n",
      "47           Cedar Waxwing      NaN\n",
      "50    Red-winged Blackbird      NaN\n",
      "103           Barn Swallow      NaN\n",
      "166   Red-winged Blackbird      NaN\n",
      "322          American Crow      NaN\n",
      "...                    ...      ...\n",
      "8215         American Crow      NaN\n",
      "8239             Fish Crow      NaN\n",
      "8244         Cedar Waxwing      NaN\n",
      "8245     Unidentified Crow      NaN\n",
      "8425         American Crow      NaN\n",
      "\n",
      "[92 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(forest_merged_df[forest_merged_df['Distance'].isnull()][['Common_Name', 'Distance']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a9ea8",
   "metadata": {},
   "source": [
    "To get the count of the birds Common_Name wise where Distance is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35fc1316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Common Names with null Distance:\n",
      "Common_Name\n",
      "Common Grackle              17\n",
      "American Crow               13\n",
      "Cedar Waxwing                8\n",
      "American Goldfinch           6\n",
      "Canada Goose                 5\n",
      "Blue Jay                     5\n",
      "Great Blue Heron             4\n",
      "Mourning Dove                4\n",
      "Turkey Vulture               4\n",
      "Chimney Swift                3\n",
      "Unidentified Crow            3\n",
      "Fish Crow                    3\n",
      "American Robin               2\n",
      "Red-winged Blackbird         2\n",
      "Barn Swallow                 2\n",
      "Double-crested Cormorant     2\n",
      "European Starling            2\n",
      "Red-shouldered Hawk          2\n",
      "Wood Duck                    1\n",
      "Mallard                      1\n",
      "Green Heron                  1\n",
      "Peregrine Falcon             1\n",
      "Pileated Woodpecker          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "common_name_null_distance_counts = (\n",
    "    forest_merged_df[forest_merged_df['Distance'].isnull()]\n",
    "    ['Common_Name']\n",
    "    .value_counts(dropna=True)\n",
    ")\n",
    "\n",
    "print(\"Count of Common Names with null Distance:\")\n",
    "print(common_name_null_distance_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305812a0",
   "metadata": {},
   "source": [
    "There are 92 nulls in Distance column. Fill the nulls in Distance with the most frequent Distance for that particular Common_Name of the species in that particular Plot_Name :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to fill null Distance with the mode within each Plot_Name + Common_Name group\n",
    "def fill_distance_with_mode_by_group(group):\n",
    "    if group['Distance'].isnull().any():\n",
    "        mode_val = group['Distance'].mode()\n",
    "        if not mode_val.empty:\n",
    "            group['Distance'] = group['Distance'].fillna(mode_val[0])\n",
    "    return group\n",
    "\n",
    "# Apply group-wise operation\n",
    "forest_merged_df = (\n",
    "    forest_merged_df\n",
    "    .groupby(['Plot_Name', 'Common_Name'], group_keys=False)\n",
    "    .apply(fill_distance_with_mode_by_group)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b0eff",
   "metadata": {},
   "source": [
    "To check if the nulls were updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89ff82aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining nulls in Distance column: 57\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining nulls in Distance column:\", forest_merged_df['Distance'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94232c93",
   "metadata": {},
   "source": [
    "There are still 57 nulls in Distance column. Fill the nulls in Distance with the most frequent Distance for that particular Common_Name of the species in that particular Admin_Unit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to fill null Distance with the mode within each Admin_Unit_Code + Common_Name group\n",
    "def fill_distance_with_mode_by_group(group):\n",
    "    if group['Distance'].isnull().any():\n",
    "        mode_val = group['Distance'].mode()\n",
    "        if not mode_val.empty:\n",
    "            group['Distance'] = group['Distance'].fillna(mode_val[0])\n",
    "    return group\n",
    "\n",
    "# Apply group-wise operation\n",
    "forest_merged_df = (\n",
    "    forest_merged_df\n",
    "    .groupby(['Admin_Unit_Code', 'Common_Name'], group_keys=False)\n",
    "    .apply(fill_distance_with_mode_by_group)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "251c6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining nulls in Distance column: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining nulls in Distance column:\", forest_merged_df['Distance'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18616b",
   "metadata": {},
   "source": [
    "There are still 10 rows with nulls in Distance because the most frequent value of Distance for these Common_Name in the particular Admin_Unit_Code is itself null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d64e20ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common_Name values with unfilled nulls in Distance:\n",
      "['Barn Swallow' 'Peregrine Falcon' 'Turkey Vulture' 'Chimney Swift'\n",
      " 'Canada Goose' 'Fish Crow' 'Unidentified Crow']\n"
     ]
    }
   ],
   "source": [
    "# Find Common_Name groups where Distance is still null\n",
    "unfilled_common_names = (\n",
    "    forest_merged_df[forest_merged_df['Distance'].isnull()]\n",
    "    ['Common_Name']\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "print(\"Common_Name values with unfilled nulls in Distance:\")\n",
    "print(unfilled_common_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3089f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Common_Name  Null_Distance_Count\n",
      "5     Turkey Vulture                    3\n",
      "0       Barn Swallow                    2\n",
      "1       Canada Goose                    1\n",
      "2      Chimney Swift                    1\n",
      "3          Fish Crow                    1\n",
      "4   Peregrine Falcon                    1\n",
      "6  Unidentified Crow                    1\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where Distance is still null\n",
    "null_distance_df = forest_merged_df[forest_merged_df['Distance'].isnull()]\n",
    "\n",
    "# Group by Common_Name and count how many such rows exist\n",
    "unfilled_counts = null_distance_df.groupby('Common_Name').size().reset_index(name='Null_Distance_Count')\n",
    "\n",
    "# Sort descending by count\n",
    "unfilled_counts = unfilled_counts.sort_values(by='Null_Distance_Count', ascending=False)\n",
    "\n",
    "print(unfilled_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac9c05",
   "metadata": {},
   "source": [
    "So from above, we see only 10 rows exists, where the Distance is null because there are no rows with no nulls for these types of birds in that particular Admin_Unit. We can assume the most frequent distance of the entire Admin_Unit in these cases and fill with that value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b60b1d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null Distance values: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Step 3: Find Admin_Unit_Code groups where Distance is still null\n",
    "still_null = forest_merged_df[forest_merged_df['Distance'].isnull()]\n",
    "\n",
    "#  For each Admin_Unit_Code with remaining nulls, fill those nulls with mode Distance of entire Admin_Unit_Code\n",
    "for admin_unit in still_null['Admin_Unit_Code'].unique():\n",
    "    # Calculate mode of Distance for this Admin_Unit_Code (excluding nulls)\n",
    "    admin_mode = forest_merged_df.loc[\n",
    "        (forest_merged_df['Admin_Unit_Code'] == admin_unit) & \n",
    "        (forest_merged_df['Distance'].notnull()), 'Distance'\n",
    "    ].mode()\n",
    "    \n",
    "    if not admin_mode.empty:\n",
    "        # Fill null Distance for this Admin_Unit_Code with its mode\n",
    "        forest_merged_df.loc[\n",
    "            (forest_merged_df['Admin_Unit_Code'] == admin_unit) & \n",
    "            (forest_merged_df['Distance'].isnull()), 'Distance'\n",
    "        ] = admin_mode[0]\n",
    "\n",
    "\n",
    "# Confirm no nulls remain\n",
    "print(\"Remaining null Distance values:\", forest_merged_df['Distance'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b28b2",
   "metadata": {},
   "source": [
    "List unique 'AccceptedTSN' values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db21ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in AcceptedTSN:\n",
      "[179276. 178775. 178195. 179064. 178620. 179124. 554256. 177125. 179443.\n",
      " 178581. 554383. 178359. 179731. 179150. 554138. 950039. 179801. 178259.\n",
      " 179435. 179083. 178309. 179853. 178532. 179680. 179236. 179045. 178166.\n",
      " 179112. 179021. 553526. 178339. 178262. 179009. 179492. 179333. 178448.\n",
      " 179777. 179759. 178329.     nan 177831. 179104. 179883. 178279. 950033.\n",
      " 176136. 950029. 178927. 178154. 178979. 179788. 950009. 178844. 178850.\n",
      " 178541. 950079. 178627. 178625. 178944. 950041. 179737. 175122. 174793.\n",
      " 178119. 950049. 179023. 175359. 554382. 950010. 174999. 950042. 174773.\n",
      " 177921. 178991. 950045. 179488. 174717. 179724. 175063. 178443. 178032.\n",
      " 178001. 178937. 175590. 175272. 178964. 950011. 179637. 179628. 179410.\n",
      " 175265. 175604. 179034. 179796. 950052. 950036. 950061. 847323. 950031.\n",
      " 950046. 950035. 179888. 176520. 178277. 950106. 950097. 178186. 175350.]\n"
     ]
    }
   ],
   "source": [
    "unique_accepted_tsn = forest_merged_df['AcceptedTSN'].unique()\n",
    "print(\"Unique values in AcceptedTSN:\")\n",
    "print(unique_accepted_tsn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ee6f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from Common_Name to its most frequent non-null AcceptedTSN\n",
    "accepted_tsn_map = (\n",
    "    forest_merged_df[forest_merged_df['AcceptedTSN'].notnull()]\n",
    "    .groupby('Common_Name')['AcceptedTSN']\n",
    "    .agg(lambda x: x.mode().iloc[0])  # pick the most frequent AcceptedTSN if multiple\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Function to fill AcceptedTSN from mapping\n",
    "def fill_accepted_tsn(row):\n",
    "    if pd.isnull(row['AcceptedTSN']):\n",
    "        return accepted_tsn_map.get(row['Common_Name'], row['AcceptedTSN'])\n",
    "    else:\n",
    "        return row['AcceptedTSN']\n",
    "\n",
    "# Apply the function row-wise\n",
    "forest_merged_df['AcceptedTSN'] = forest_merged_df.apply(fill_accepted_tsn, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39613995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining nulls in AcceptedTSN: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining nulls in AcceptedTSN:\", forest_merged_df['AcceptedTSN'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70c89e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Common_Name  AcceptedTSN  Filled_AcceptedTSN\n",
      "165   House Finch          NaN                 NaN\n",
      "635   House Finch          NaN                 NaN\n",
      "638   House Finch          NaN                 NaN\n",
      "1337  House Finch          NaN                 NaN\n",
      "3708  House Finch          NaN                 NaN\n",
      "3912  House Finch          NaN                 NaN\n",
      "3920  House Finch          NaN                 NaN\n",
      "3921  House Finch          NaN                 NaN\n",
      "4034  House Finch          NaN                 NaN\n"
     ]
    }
   ],
   "source": [
    "# First, create a mapping from Common_Name to the most frequent non-null AcceptedTSN\n",
    "accepted_tsn_map = (\n",
    "    forest_merged_df[forest_merged_df['AcceptedTSN'].notnull()]\n",
    "    .groupby('Common_Name')['AcceptedTSN']\n",
    "    .agg(lambda x: x.mode().iloc[0])  # most frequent AcceptedTSN per Common_Name\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Now, filter rows where AcceptedTSN is null\n",
    "null_accepted_tsn_rows = forest_merged_df[forest_merged_df['AcceptedTSN'].isnull()]\n",
    "\n",
    "# For each such row, get the AcceptedTSN from the mapping\n",
    "null_accepted_tsn_rows = null_accepted_tsn_rows.copy()  # avoid SettingWithCopyWarning\n",
    "null_accepted_tsn_rows['Filled_AcceptedTSN'] = null_accepted_tsn_rows['Common_Name'].map(accepted_tsn_map)\n",
    "\n",
    "# Show the results: Common_Name, current null AcceptedTSN, and the mapped AcceptedTSN to fill\n",
    "print(null_accepted_tsn_rows[['Common_Name', 'AcceptedTSN', 'Filled_AcceptedTSN']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743bb0d",
   "metadata": {},
   "source": [
    "Now we can fill the AcceptedTSN for House Finch which are nulls as 'Unknown':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37dbd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df['AcceptedTSN'] = forest_merged_df['AcceptedTSN'].fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55f8c8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[179276.0 178775.0 178195.0 179064.0 178620.0 179124.0 554256.0 177125.0\n",
      " 179443.0 178581.0 554383.0 178359.0 179731.0 179150.0 554138.0 950039.0\n",
      " 179801.0 178259.0 179435.0 179083.0 178309.0 179853.0 178532.0 179680.0\n",
      " 179236.0 179045.0 178166.0 179112.0 179021.0 553526.0 178339.0 178262.0\n",
      " 179009.0 179492.0 179333.0 178448.0 179777.0 179759.0 178329.0 'Unknown'\n",
      " 177831.0 179104.0 179883.0 178279.0 950033.0 176136.0 950029.0 178927.0\n",
      " 178154.0 178979.0 179788.0 950009.0 178844.0 178850.0 178541.0 950079.0\n",
      " 178627.0 178625.0 178944.0 950041.0 179737.0 175122.0 174793.0 178119.0\n",
      " 950049.0 179023.0 175359.0 554382.0 950010.0 174999.0 950042.0 174773.0\n",
      " 177921.0 178991.0 950045.0 179488.0 174717.0 179724.0 175063.0 178443.0\n",
      " 178032.0 178001.0 178937.0 175590.0 175272.0 178964.0 950011.0 179637.0\n",
      " 179628.0 179410.0 175265.0 175604.0 179034.0 179796.0 950052.0 950036.0\n",
      " 950061.0 847323.0 950031.0 950046.0 950035.0 179888.0 176520.0 178277.0\n",
      " 950106.0 950097.0 178186.0 175350.0]\n"
     ]
    }
   ],
   "source": [
    "print(forest_merged_df['AcceptedTSN'].isnull().sum())  # Should return 0\n",
    "print(forest_merged_df['AcceptedTSN'].unique())        # To verify 'Unknown' is included\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3a70e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ The DataFrame has no null values.\n"
     ]
    }
   ],
   "source": [
    "# Returns True if any nulls exist, else False\n",
    "has_nulls = forest_merged_df.isnull().values.any()\n",
    "\n",
    "if has_nulls:\n",
    "    print(\"There are still null values in the DataFrame.\")\n",
    "    # Optional: show which columns have nulls\n",
    "    print(forest_merged_df.isnull().sum())\n",
    "else:\n",
    "    print(\"✅ The DataFrame has no null values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af201cef",
   "metadata": {},
   "source": [
    "To check if any duplicates in forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a324ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 duplicate rows in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Count total number of duplicate rows\n",
    "duplicate_count = forest_merged_df.duplicated().sum()\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(f\"There are {duplicate_count} duplicate rows in the DataFrame.\")\n",
    "else:\n",
    "    print(\"✅ No duplicate rows found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbd712",
   "metadata": {},
   "source": [
    "To print the original + duplicates in forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f741f818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Admin_Unit_Code Site_Name  Plot_Name Location_Type  Year       Date  \\\n",
      "2233            CHOH   CHOH 18  CHOH-1256        Forest  2018 2018-06-13   \n",
      "2234            CHOH   CHOH 18  CHOH-1256        Forest  2018 2018-06-13   \n",
      "3529            GWMP    GWMP 4  GWMP-0120        Forest  2018 2018-06-29   \n",
      "3532            GWMP    GWMP 4  GWMP-0120        Forest  2018 2018-06-29   \n",
      "5549            NACE    NACE 2  NACE-0477        Forest  2018 2018-05-11   \n",
      "5558            NACE    NACE 2  NACE-0477        Forest  2018 2018-05-11   \n",
      "7163            PRWI   PRWI 14  PRWI-0660        Forest  2018 2018-07-03   \n",
      "7166            PRWI   PRWI 14  PRWI-0660        Forest  2018 2018-07-03   \n",
      "\n",
      "     Start_Time  End_Time          Observer  Visit  ... NPSTaxonCode AOU_Code  \\\n",
      "2233   08:17:00  08:27:00  Elizabeth Oswald      1  ...        77770     MALL   \n",
      "2234   08:17:00  08:27:00  Elizabeth Oswald      1  ...        77770     MALL   \n",
      "3529   09:40:00  09:50:00  Elizabeth Oswald      2  ...       265876     CACH   \n",
      "3532   09:40:00  09:50:00  Elizabeth Oswald      2  ...       265876     CACH   \n",
      "5549   08:57:00  09:07:00  Elizabeth Oswald      1  ...        84865     RBWO   \n",
      "5558   08:57:00  09:07:00  Elizabeth Oswald      1  ...        84865     RBWO   \n",
      "7163   09:00:00  09:10:00  Elizabeth Oswald      2  ...        93587     REVI   \n",
      "7166   09:00:00  09:10:00  Elizabeth Oswald      2  ...        93587     REVI   \n",
      "\n",
      "     PIF_Watchlist_Status  Regional_Stewardship_Status Temperature   Humidity  \\\n",
      "2233                False                        False   21.000000  84.099998   \n",
      "2234                False                        False   21.000000  84.099998   \n",
      "3529                False                         True   26.700001  72.000000   \n",
      "3532                False                         True   26.700001  72.000000   \n",
      "5549                False                        False   24.100000  77.500000   \n",
      "5558                False                        False   24.100000  77.500000   \n",
      "7163                False                        False   26.500000  87.199997   \n",
      "7166                False                        False   26.500000  87.199997   \n",
      "\n",
      "                      Sky                                        Wind  \\\n",
      "2233      Cloudy/Overcast  Gentle breeze (8-12 mph), leaves in motion   \n",
      "2234      Cloudy/Overcast  Gentle breeze (8-12 mph), leaves in motion   \n",
      "3529  Clear or Few Clouds    Light breeze (4-7 mph) wind felt on face   \n",
      "3532  Clear or Few Clouds    Light breeze (4-7 mph) wind felt on face   \n",
      "5549  Clear or Few Clouds   Light air movement (1-3 mph) smoke drifts   \n",
      "5558  Clear or Few Clouds   Light air movement (1-3 mph) smoke drifts   \n",
      "7163  Clear or Few Clouds    Light breeze (4-7 mph) wind felt on face   \n",
      "7166  Clear or Few Clouds    Light breeze (4-7 mph) wind felt on face   \n",
      "\n",
      "                 Disturbance Initial_Three_Min_Cnt  \n",
      "2233  Slight effect on count                 False  \n",
      "2234  Slight effect on count                 False  \n",
      "3529  Slight effect on count                  True  \n",
      "3532  Slight effect on count                  True  \n",
      "5549  Slight effect on count                  True  \n",
      "5558  Slight effect on count                  True  \n",
      "7163  Slight effect on count                  True  \n",
      "7166  Slight effect on count                  True  \n",
      "\n",
      "[8 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# This will include both the original and its duplicates\n",
    "duplicates_all = forest_merged_df[forest_merged_df.duplicated(keep=False)]\n",
    "print(duplicates_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d2657",
   "metadata": {},
   "source": [
    "Now we can drop the duplicates and keep the first instance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2bab966",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df = forest_merged_df.drop_duplicates(keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da9a9d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Remaining duplicates: {forest_merged_df.duplicated().sum()}\")  # Should be 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2eb5c2",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the Scientific_Name should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11e295a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single Scientific_Name.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique Scientific_Name entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['Scientific_Name'].nunique()\n",
    "\n",
    "# Find where more than one Scientific_Name exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ Scientific_Name mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single Scientific_Name.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f3e87",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the AcceptedTSN should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07eeea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single AcceptedTSN.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique AcceptedTSN entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['AcceptedTSN'].nunique()\n",
    "\n",
    "# Find where more than one AcceptedTSN exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ AcceptedTSN mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single AcceptedTSN.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fbaa1",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the NPSTaxonCode should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf8fa14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single NPSTaxonCode.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique NPSTaxonCode entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['NPSTaxonCode'].nunique()\n",
    "\n",
    "# Find where more than one NPSTaxonCode exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ NPSTaxonCode mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single NPSTaxonCode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22399487",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the AOU_Code should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8256dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single AOU_Code.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique AOU_Code entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['AOU_Code'].nunique()\n",
    "\n",
    "# Find where more than one AOU_Code exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ AOU_Code mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single AOU_Code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd2755",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the PIF_Watchlist_Status should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff6919a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single PIF_Watchlist_Status.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique PIF_Watchlist_Status entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['PIF_Watchlist_Status'].nunique()\n",
    "\n",
    "# Find where more than one PIF_Watchlist_Status exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ PIF_Watchlist_Status mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single PIF_Watchlist_Status.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5d603",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the Regional_Stewardship_Status should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "895e2960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single Regional_Stewardship_Status.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique Regional_Stewardship_Status entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['Regional_Stewardship_Status'].nunique()\n",
    "\n",
    "# Find where more than one Regional_Stewardship_Status exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ Regional_Stewardship_Status mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single Regional_Stewardship_Status.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a1f7a",
   "metadata": {},
   "source": [
    "Findings: Fron the above we find that for every Common_Name there is a single Scientific_Name, AcceptedTSN, NPSTaxonCode, AOU_Code, PIF_Watchlist_Status, and Regional_Stewardship_Status. So these columns can be combined togoether in a table indexed on the Common_Name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a55ab",
   "metadata": {},
   "source": [
    "To check if each unique Plot_Name always maps to the same Admin_Unit_Code and Site_Name in forest_merged_df, we can group by Plot_Name and count unique values in the other two columns and find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a837edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Plot_Name has consistent Admin_Unit_Code and Site_Name.\n"
     ]
    }
   ],
   "source": [
    "# Group by Plot_Name and count unique Admin_Unit_Code and Site_Name\n",
    "consistency_check = forest_merged_df.groupby('Plot_Name')[['Admin_Unit_Code', 'Site_Name']].nunique()\n",
    "\n",
    "# Find Plot_Names with more than one unique value in either column\n",
    "inconsistent_plots = consistency_check[(consistency_check['Admin_Unit_Code'] > 1) | \n",
    "                                       (consistency_check['Site_Name'] > 1)] \n",
    "\n",
    "# Output the inconsistencies\n",
    "if not inconsistent_plots.empty:\n",
    "    print(\"❌ Inconsistencies found for the following Plot_Name(s):\")\n",
    "    print(inconsistent_plots)\n",
    "else:\n",
    "    print(\"✅ Each Plot_Name has consistent Admin_Unit_Code and Site_Name.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614a24b",
   "metadata": {},
   "source": [
    "Findings: Fron the above we find that for every Plot_Name there is a single Admin_Unit_Code and Site_Name. So these columns can be combined togoether in a table indexed on the Plot_Name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca81962",
   "metadata": {},
   "source": [
    "Now to analyse the data types of the columns in forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e28d654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Admin_Unit_Code                        object\n",
       "Site_Name                              object\n",
       "Plot_Name                              object\n",
       "Location_Type                          object\n",
       "Year                                    int64\n",
       "Date                           datetime64[ns]\n",
       "Start_Time                             object\n",
       "End_Time                               object\n",
       "Observer                               object\n",
       "Visit                                   int64\n",
       "Interval_Length                        object\n",
       "ID_Method                              object\n",
       "Distance                               object\n",
       "Flyover_Observed                         bool\n",
       "Sex                                    object\n",
       "Common_Name                            object\n",
       "Scientific_Name                        object\n",
       "AcceptedTSN                            object\n",
       "NPSTaxonCode                            int64\n",
       "AOU_Code                               object\n",
       "PIF_Watchlist_Status                     bool\n",
       "Regional_Stewardship_Status              bool\n",
       "Temperature                           float64\n",
       "Humidity                              float64\n",
       "Sky                                    object\n",
       "Wind                                   object\n",
       "Disturbance                            object\n",
       "Initial_Three_Min_Cnt                    bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_merged_df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99d4aa",
   "metadata": {},
   "source": [
    "Now the Start_Time and End_Time are in object format (string) which needs to be converted and only Time should be present :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "034c8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df['Start_Time'] = pd.to_datetime(forest_merged_df['Start_Time'], format='%H:%M:%S', errors='coerce').dt.time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146db975",
   "metadata": {},
   "source": [
    "To confirm if the Start_Time is of correct class datetime.time :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f640a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'datetime.time'>], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_merged_df['Start_Time'].apply(type).unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da43654",
   "metadata": {},
   "source": [
    "Now check for End_Time and do the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b74f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df['End_Time'] = pd.to_datetime(forest_merged_df['End_Time'], format='%H:%M:%S', errors='coerce').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83b9a4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'datetime.time'>], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_merged_df['Start_Time'].apply(type).unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74b188",
   "metadata": {},
   "source": [
    "GRASSLAND DATA CLEANING AND PRE PROCESSING:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e609b76",
   "metadata": {},
   "source": [
    "To list down the columns with nulls in Grassland df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24ba1ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sub_Unit_Code', 'ID_Method', 'Distance', 'AcceptedTSN', 'TaxonCode']\n"
     ]
    }
   ],
   "source": [
    "null_columns = grassland_merged_df.columns[grassland_merged_df.isnull().any()].tolist()\n",
    "print(null_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd2ca3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bbb45cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub_Unit_Code    8531\n",
      "ID_Method           1\n",
      "Distance         1394\n",
      "AcceptedTSN        24\n",
      "TaxonCode           2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List of target columns\n",
    "columns_to_check = ['Sub_Unit_Code', 'ID_Method', 'Distance', 'AcceptedTSN', 'TaxonCode']\n",
    "\n",
    "# Count nulls in each column\n",
    "null_counts = grassland_merged_df[columns_to_check].isnull().sum()\n",
    "\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ea35add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grassland_merged_df['Sub_Unit_Code'].dropna().unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd9fc5",
   "metadata": {},
   "source": [
    "The Sub_Unit_Code is entire column with nulls in grassland_merged_df and the column can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e967ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df.drop(columns=['Sub_Unit_Code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b60102",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9fdfec",
   "metadata": {},
   "source": [
    "To print the single row where  'ID_Method' is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_null_id = grassland_merged_df[grassland_merged_df['ID_Method'].isnull()]\n",
    "print(rows_with_null_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7447de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Singing' 'Calling' 'Visualization']\n"
     ]
    }
   ],
   "source": [
    "unique_id_methods = grassland_merged_df['ID_Method'].dropna().unique()\n",
    "print(unique_id_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895e7bf",
   "metadata": {},
   "source": [
    "Get Common_Name where ID_Method is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00e8bd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['American Crow']\n"
     ]
    }
   ],
   "source": [
    "common_names_with_null_id_method = grassland_merged_df.loc[grassland_merged_df['ID_Method'].isnull(), 'Common_Name'].unique()\n",
    "print(common_names_with_null_id_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0d8f4a",
   "metadata": {},
   "source": [
    "To fill the ID_Method which is null with the most frequent ID_Method for the same Common_Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill null ID_Method with mode for each Common_Name group\n",
    "def fill_id_method_mode(group):\n",
    "    if group['ID_Method'].isnull().any():\n",
    "        mode_value = group['ID_Method'].mode()\n",
    "        if not mode_value.empty:\n",
    "            group['ID_Method'] = group['ID_Method'].fillna(mode_value[0])\n",
    "    return group\n",
    "\n",
    "# Apply the function grouped by Common_Name\n",
    "grassland_merged_df = grassland_merged_df.groupby('Common_Name', group_keys=False).apply(fill_id_method_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625826e",
   "metadata": {},
   "source": [
    "To verify if the null value is filled and confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd78927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(grassland_merged_df['ID_Method'].isnull().sum())  # Should print 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b970d61",
   "metadata": {},
   "source": [
    "To get the Distance which are null Common_Name wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8453bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Common Names with null Distance:\n",
      "Common_Name\n",
      "European Starling                321\n",
      "Cedar Waxwing                    255\n",
      "Common Grackle                   127\n",
      "Barn Swallow                     127\n",
      "American Goldfinch               101\n",
      "Red-winged Blackbird              83\n",
      "Mourning Dove                     52\n",
      "Turkey Vulture                    44\n",
      "Brown-headed Cowbird              34\n",
      "American Crow                     32\n",
      "Tree Swallow                      29\n",
      "Blue Jay                          20\n",
      "American Robin                    20\n",
      "Northern Rough-winged Swallow     16\n",
      "Unidentified Crow                 14\n",
      "Canada Goose                      14\n",
      "Great Blue Heron                  12\n",
      "Unidentified Swallow              11\n",
      "Rock Dove                         11\n",
      "Fish Crow                         10\n",
      "Killdeer                           7\n",
      "Northern Cardinal                  6\n",
      "Bald Eagle                         5\n",
      "House Finch                        5\n",
      "American Kestrel                   5\n",
      "Chimney Swift                      4\n",
      "Purple Martin                      3\n",
      "Eastern Bluebird                   3\n",
      "Eastern Kingbird                   3\n",
      "Indigo Bunting                     3\n",
      "Northern Mockingbird               3\n",
      "Red-tailed Hawk                    2\n",
      "Black Vulture                      2\n",
      "Eastern Meadowlark                 2\n",
      "Baltimore Oriole                   2\n",
      "Wood Duck                          1\n",
      "Ruby-throated Hummingbird          1\n",
      "Red-shouldered Hawk                1\n",
      "Gray Catbird                       1\n",
      "Pileated Woodpecker                1\n",
      "Red-bellied Woodpecker             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "common_name_null_distance_counts = (\n",
    "    grassland_merged_df[grassland_merged_df['Distance'].isnull()]\n",
    "    ['Common_Name']\n",
    "    .value_counts(dropna=True)\n",
    ")\n",
    "print(\"Count of Common Names with null Distance:\")\n",
    "print(common_name_null_distance_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71840fa2",
   "metadata": {},
   "source": [
    "There are 1394 nulls in Distance Column. Fill the nulls in Distance with the most frequent Distance for that particular Common_Name of the species in that particular Plot_Name :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to fill null Distance with the mode within each Plot_Name + Common_Name group\n",
    "def fill_distance_with_mode_by_group(group):\n",
    "    if group['Distance'].isnull().any():\n",
    "        mode_val = group['Distance'].mode()\n",
    "        if not mode_val.empty:\n",
    "            group['Distance'] = group['Distance'].fillna(mode_val[0])\n",
    "    return group\n",
    "\n",
    "# Apply group-wise operation\n",
    "grassland_merged_df = (\n",
    "    grassland_merged_df\n",
    "    .groupby(['Plot_Name', 'Common_Name'], group_keys=False)\n",
    "    .apply(fill_distance_with_mode_by_group)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed9b34",
   "metadata": {},
   "source": [
    "To check if the nulls were updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b41cda79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining nulls in Distance column: 748\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining nulls in Distance column:\", grassland_merged_df['Distance'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbedeab",
   "metadata": {},
   "source": [
    "There are still 748 rows with nulls in Distance because the most frequent value of Distance for these Common_Name in the particular Plot_Name is itself null. Now fill the nulls in Distance with the most frequent Distance for that particular Common_Name of the species in that particular Admin_Unit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921eb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to fill null Distance with the mode within each Admin_Unit_Code + Common_Name group\n",
    "def fill_distance_with_mode_by_group(group):\n",
    "    if group['Distance'].isnull().any():\n",
    "        mode_val = group['Distance'].mode()\n",
    "        if not mode_val.empty:\n",
    "            group['Distance'] = group['Distance'].fillna(mode_val[0])\n",
    "    return group\n",
    "\n",
    "# Apply group-wise operation\n",
    "grassland_merged_df = (\n",
    "    grassland_merged_df\n",
    "    .groupby(['Admin_Unit_Code', 'Common_Name'], group_keys=False)\n",
    "    .apply(fill_distance_with_mode_by_group)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd675975",
   "metadata": {},
   "source": [
    "To check if the nulls were updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfc28ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining nulls in Distance column: 49\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining nulls in Distance column:\", grassland_merged_df['Distance'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ea629",
   "metadata": {},
   "source": [
    "There are still 49 rows with nulls in Distance because the most frequent value of Distance for these Common_Name in the particular Admin_Unit_Code is itself null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b7c68cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common_Name values with unfilled nulls in Distance:\n",
      "['Bald Eagle' 'Wood Duck' 'Unidentified Crow' 'Canada Goose'\n",
      " 'Great Blue Heron' 'Purple Martin' 'Unidentified Swallow' 'Black Vulture'\n",
      " 'American Kestrel']\n"
     ]
    }
   ],
   "source": [
    "# Find Common_Name groups where Distance is still null\n",
    "unfilled_common_names = (\n",
    "    grassland_merged_df[grassland_merged_df['Distance'].isnull()]\n",
    "    ['Common_Name']\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "print(\"Common_Name values with unfilled nulls in Distance:\")\n",
    "print(unfilled_common_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "acf509f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Common_Name  Null_Distance_Count\n",
      "4      Great Blue Heron                   12\n",
      "7  Unidentified Swallow                   11\n",
      "6     Unidentified Crow                    7\n",
      "3          Canada Goose                    6\n",
      "1            Bald Eagle                    5\n",
      "0      American Kestrel                    3\n",
      "5         Purple Martin                    3\n",
      "2         Black Vulture                    1\n",
      "8             Wood Duck                    1\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where Distance is still null\n",
    "null_distance_df = grassland_merged_df[grassland_merged_df['Distance'].isnull()]\n",
    "\n",
    "# Group by Common_Name and count how many such rows exist\n",
    "unfilled_counts = null_distance_df.groupby('Common_Name').size().reset_index(name='Null_Distance_Count')\n",
    "\n",
    "# Sort descending by count\n",
    "unfilled_counts = unfilled_counts.sort_values(by='Null_Distance_Count', ascending=False)\n",
    "\n",
    "print(unfilled_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48785b",
   "metadata": {},
   "source": [
    "So from above, we see only 49 rows exists, where the Distance is null because there are no rows with no nulls for these types of birds in that particular Admin_Unit. \n",
    "We can assume the most frequent distance of the entire Admin_Unit in these cases and fill with that value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e5c9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Find Admin_Unit_Code groups where Distance is still null\n",
    "still_null = grassland_merged_df[grassland_merged_df['Distance'].isnull()]\n",
    "\n",
    "#  For each Admin_Unit_Code with remaining nulls, fill those nulls with mode Distance of entire Admin_Unit_Code\n",
    "for admin_unit in still_null['Admin_Unit_Code'].unique():\n",
    "    # Calculate mode of Distance for this Admin_Unit_Code (excluding nulls)\n",
    "    admin_mode = grassland_merged_df.loc[\n",
    "        (grassland_merged_df['Admin_Unit_Code'] == admin_unit) & \n",
    "        (grassland_merged_df['Distance'].notnull()), 'Distance'\n",
    "    ].mode()\n",
    "    \n",
    "    if not admin_mode.empty:\n",
    "        # Fill null Distance for this Admin_Unit_Code with its mode\n",
    "        grassland_merged_df.loc[\n",
    "            (grassland_merged_df['Admin_Unit_Code'] == admin_unit) & \n",
    "            (grassland_merged_df['Distance'].isnull()), 'Distance'\n",
    "        ] = admin_mode[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e974d",
   "metadata": {},
   "source": [
    " Confirm no nulls remain in Distance in grassland df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae853134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null Distance values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining null Distance values:\", grassland_merged_df['Distance'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635dc66",
   "metadata": {},
   "source": [
    "List unique 'AccceptedTSN' values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d4556d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in AcceptedTSN:\n",
      "[179435. 179801. 179333. 179443. 179731. 178279. 179150. 179124. 177125.\n",
      " 179276. 179492. 178431. 178581. 950041. 179112. 179083. 179737. 178309.\n",
      " 179759. 175265. 178195. 554138. 174999. 179680. 554383. 178625. 179777.\n",
      " 179724. 554256. 178359. 179064. 178532. 178944. 179853. 178339. 178620.\n",
      " 179104. 175420. 179045. 179034. 178448. 179366. 179236. 178627. 178329.\n",
      " 553526. 178541. 178262. 179023. 178001. 175272. 179637.     nan 178154.\n",
      " 179021. 175350. 176520. 175622. 179883. 950033. 178775. 178979. 179145.\n",
      " 177831. 178259. 950045. 175122. 178166. 179628. 175359. 950052. 178964.\n",
      " 175309. 178032. 177071. 179736. 178443. 179009. 179796. 174773. 176136.\n",
      " 179888. 178991. 178341. 178927. 950035. 179788. 178464. 179314. 178423.\n",
      " 174861. 950040. 179032. 950039. 178277. 178937. 178119. 178842. 950010.\n",
      " 950061. 178844. 179462. 177921. 179488. 950036. 950031. 178344.]\n"
     ]
    }
   ],
   "source": [
    "unique_accepted_tsn = grassland_merged_df['AcceptedTSN'].unique()\n",
    "print(\"Unique values in AcceptedTSN:\")\n",
    "print(unique_accepted_tsn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf88ed",
   "metadata": {},
   "source": [
    "Check if AcceptedTSN value exists in any other row for the same Common_Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef48f172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Common_Name, AcceptedTSN]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get Common_Name values where AcceptedTSN is null\n",
    "common_names_with_null_acceptedtsn = grassland_merged_df.loc[grassland_merged_df['AcceptedTSN'].isna(), 'Common_Name'].unique()\n",
    "\n",
    "# Step 2: Filter rows with those Common_Names and where AcceptedTSN is NOT null\n",
    "rows_with_taxoncode = grassland_merged_df[\n",
    "    (grassland_merged_df['Common_Name'].isin(common_names_with_null_acceptedtsn)) &\n",
    "    (grassland_merged_df['AcceptedTSN'].notna())\n",
    "]\n",
    "\n",
    "# Step 3: See if any AcceptedTSN exists for those Common_Names\n",
    "print(rows_with_taxoncode[['Common_Name', 'AcceptedTSN']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097f780",
   "metadata": {},
   "source": [
    "To fill all nulls in AcceptedTSN with 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bc1772c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df['AcceptedTSN'] = grassland_merged_df['AcceptedTSN'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e091c",
   "metadata": {},
   "source": [
    "To check TaxonCode for nulls: List unique TaxonCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b108a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in TaxonCode:\n",
      "[ 84781.  87184.  83867.  84790.  87106.  85757.  94257.  94228.  82737.\n",
      "  83803.  85643.  87391.  88350. 773819.  94215.  93655.  87112.  85791.\n",
      "  87136.  79468.  84865. 266957.  76625.  86252. 265876.  89977.  87156.\n",
      "  87098. 264079.  85846.  93634.  88296.  92708.  88038.  85824.  88394.\n",
      "  94206.  80444.  93613.  93601.  87409.  84704.  95286.  89979.  85813.\n",
      " 263793.  88306.  85739.  93589.  83046.  79476.  86204. 926917.  84820.\n",
      "  93587.  79563.  77646.  82543.  88071. 890949.  90935.  92746.  94251.\n",
      "  89102.  84936. 890952.  77836.  84833.  86194.  79572. 890945.  92730.\n",
      "  79517.  83884.  82677.     nan  87404.  93573.  87177.  84416.  86451.\n",
      "  88076.  93552.  85827.  92689. 774021.  87168.  87427.  83846.  87382.\n",
      " 773820.  93599. 773778.  85755.  92700.  83980.  91010. 773765. 890946.\n",
      "  91012.  85610.  82956.  85638. 890943. 773818.  85830.]\n"
     ]
    }
   ],
   "source": [
    "unique_taxoncode = grassland_merged_df['TaxonCode'].unique()\n",
    "print(\"Unique values in TaxonCode:\")\n",
    "print(unique_taxoncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4bfd5544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2596     Northwestern Crow\n",
      "5556    Chinese Pond-Heron\n",
      "Name: Common_Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where TaxonCode is null and get the corresponding Common_Name\n",
    "null_taxoncode_common_names = grassland_merged_df.loc[grassland_merged_df['TaxonCode'].isna(), 'Common_Name']\n",
    "print(null_taxoncode_common_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a74999fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Common_Name, TaxonCode]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get Common_Name values where TaxonCode is null\n",
    "common_names_with_null_taxoncode = grassland_merged_df.loc[grassland_merged_df['TaxonCode'].isna(), 'Common_Name'].unique()\n",
    "\n",
    "# Step 2: Filter rows with those Common_Names and where TaxonCode is NOT null\n",
    "rows_with_taxoncode = grassland_merged_df[\n",
    "    (grassland_merged_df['Common_Name'].isin(common_names_with_null_taxoncode)) &\n",
    "    (grassland_merged_df['TaxonCode'].notna())\n",
    "]\n",
    "\n",
    "# Step 3: See if any TaxonCode exists for those Common_Names\n",
    "print(rows_with_taxoncode[['Common_Name', 'TaxonCode']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c681b",
   "metadata": {},
   "source": [
    "Fill TaxonCode with nulls as 'Unknown' in grassland_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bc50b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df['TaxonCode'] = grassland_merged_df['TaxonCode'].fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "583e601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ The DataFrame has no null values.\n"
     ]
    }
   ],
   "source": [
    "# Returns True if any nulls exist, else False\n",
    "has_nulls = grassland_merged_df.isnull().values.any()\n",
    "\n",
    "if has_nulls:\n",
    "    print(\"There are still null values in the DataFrame.\")\n",
    "    # Optional: show which columns have nulls\n",
    "    print(grassland_merged_df.isnull().sum())\n",
    "else:\n",
    "    print(\"✅ The DataFrame has no null values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88697b78",
   "metadata": {},
   "source": [
    "To check if any duplicates in grassland_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "acd21ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1705 duplicate rows in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Count total number of duplicate rows\n",
    "duplicate_count = grassland_merged_df.duplicated().sum()\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(f\"There are {duplicate_count} duplicate rows in the DataFrame.\")\n",
    "else:\n",
    "    print(\"✅ No duplicate rows found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fdb46",
   "metadata": {},
   "source": [
    "To print the original + duplicates in grassland_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will include both the original and its duplicates\n",
    "duplicates_all = grassland_merged_df[grassland_merged_df.duplicated(keep=False)]\n",
    "print(duplicates_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e469c",
   "metadata": {},
   "source": [
    "Now we can drop the duplicates and keep the first instance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "13d1879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df = grassland_merged_df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "515c6079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Remaining duplicates: {grassland_merged_df.duplicated().sum()}\")  # Should be 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef56a0",
   "metadata": {},
   "source": [
    "Now to analyse the data types of the columns in grassland_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f5adf5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Admin_Unit_Code                        object\n",
       "Plot_Name                              object\n",
       "Location_Type                          object\n",
       "Year                                    int64\n",
       "Date                           datetime64[ns]\n",
       "Start_Time                             object\n",
       "End_Time                               object\n",
       "Observer                               object\n",
       "Visit                                   int64\n",
       "Interval_Length                        object\n",
       "ID_Method                              object\n",
       "Distance                               object\n",
       "Flyover_Observed                         bool\n",
       "Sex                                    object\n",
       "Common_Name                            object\n",
       "Scientific_Name                        object\n",
       "AcceptedTSN                            object\n",
       "TaxonCode                              object\n",
       "AOU_Code                               object\n",
       "PIF_Watchlist_Status                     bool\n",
       "Regional_Stewardship_Status              bool\n",
       "Temperature                           float64\n",
       "Humidity                              float64\n",
       "Sky                                    object\n",
       "Wind                                   object\n",
       "Disturbance                            object\n",
       "Previously_Obs                           bool\n",
       "Initial_Three_Min_Cnt                    bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grassland_merged_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8314494f",
   "metadata": {},
   "source": [
    "Now the Start_Time and End_Time are in object format (string) which needs to be converted and only Time should be present :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "465ba1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df['Start_Time'] = pd.to_datetime(grassland_merged_df['Start_Time'], format='%H:%M:%S', errors='coerce').dt.time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a3c5f",
   "metadata": {},
   "source": [
    "To confirm if the Start_Time is of correct class datetime.time :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "55d4cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'datetime.time'>], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grassland_merged_df['Start_Time'].apply(type).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9cb705",
   "metadata": {},
   "source": [
    "Now check for End_Time and do the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d7d9580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'datetime.time'>], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_merged_df['End_Time'] = pd.to_datetime(forest_merged_df['End_Time'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "forest_merged_df['Start_Time'].apply(type).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1282fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values are False:\n"
     ]
    }
   ],
   "source": [
    "only_false = grassland_merged_df['Previously_Obs'].eq(False).all()\n",
    "print(\"All values are False:\" if only_false else \"There are True or missing values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e87ee122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "print(grassland_merged_df['Previously_Obs'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a9c332",
   "metadata": {},
   "source": [
    "We can drop the column 'Previously_Obs' as all values are 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4538ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df.drop(columns=['Previously_Obs'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "83e4c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Admin_Unit_Code', 'Plot_Name', 'Location_Type', 'Year', 'Date',\n",
      "       'Start_Time', 'End_Time', 'Observer', 'Visit', 'Interval_Length',\n",
      "       'ID_Method', 'Distance', 'Flyover_Observed', 'Sex', 'Common_Name',\n",
      "       'Scientific_Name', 'AcceptedTSN', 'TaxonCode', 'AOU_Code',\n",
      "       'PIF_Watchlist_Status', 'Regional_Stewardship_Status', 'Temperature',\n",
      "       'Humidity', 'Sky', 'Wind', 'Disturbance', 'Initial_Three_Min_Cnt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(grassland_merged_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e5ab1fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Admin_Unit_Code', 'Site_Name', 'Plot_Name', 'Location_Type', 'Year',\n",
      "       'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
      "       'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex',\n",
      "       'Common_Name', 'Scientific_Name', 'AcceptedTSN', 'NPSTaxonCode',\n",
      "       'AOU_Code', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status',\n",
      "       'Temperature', 'Humidity', 'Sky', 'Wind', 'Disturbance',\n",
      "       'Initial_Three_Min_Cnt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(forest_merged_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dba454",
   "metadata": {},
   "source": [
    "Rename NPSTaxonCode in forest_merged_df as TaxonCode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "826bc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df.rename(columns={'NPSTaxonCode': 'TaxonCode'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbf558",
   "metadata": {},
   "source": [
    "Now creat df grassland_plot_details and forest_plot_details which stores the unique set of columns 'Admin_Unit_Code', 'Location_Type' for a particular plot_name. In case of forst_plot_details column 'Site_Name' is also added. Concatenate both to get one plot_details df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aef544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select relevant columns from both DataFrames, adding 'Site_Name' only where available\n",
    "grassland_plot_details = grassland_merged_df[['Plot_Name', 'Admin_Unit_Code', 'Location_Type']].copy()\n",
    "grassland_plot_details['Site_Name'] = pd.NA  # Add missing column with nulls\n",
    "\n",
    "forest_plot_details = forest_merged_df[['Plot_Name', 'Admin_Unit_Code', 'Location_Type', 'Site_Name']].copy()\n",
    "\n",
    "# Concatenate the two\n",
    "plot_details = pd.concat([grassland_plot_details, forest_plot_details], ignore_index=True)\n",
    "\n",
    "# Drop duplicates to ensure one row per unique Plot_Name (keeping first occurrence)\n",
    "plot_details = plot_details.drop_duplicates(subset=['Plot_Name'])\n",
    "\n",
    "# Set 'Plot_Name' as index\n",
    "plot_details.set_index('Plot_Name', inplace=True)\n",
    "\n",
    "# Final Plot_Details table\n",
    "Plot_Details = plot_details\n",
    "\n",
    "# Display result (optional)\n",
    "print(Plot_Details.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f34713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609, 3)\n"
     ]
    }
   ],
   "source": [
    "print(plot_details.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a973d",
   "metadata": {},
   "source": [
    "Create species_details df with the columns 'Common_Name', 'Scientific_Name', 'AcceptedTSN', 'TaxonCode',\n",
    "    'AOU_Code', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status' as all these values are unique for a particular Common Name. Also the index can be the Common_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "402cf66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Scientific_Name AcceptedTSN TaxonCode AOU_Code  \\\n",
      "Common_Name                                                                 \n",
      "Chipping Sparrow        Spizella passerina    179435.0   84781.0     CHSP   \n",
      "Eastern Bluebird             Sialia sialis    179801.0   87184.0     EABL   \n",
      "Grasshopper Sparrow  Ammodramus savannarum    179333.0   83867.0     GRSP   \n",
      "Field Sparrow             Spizella pusilla    179443.0   84790.0     FISP   \n",
      "American Crow        Corvus brachyrhynchos    179731.0   87106.0     AMCR   \n",
      "\n",
      "                     PIF_Watchlist_Status  Regional_Stewardship_Status  \n",
      "Common_Name                                                             \n",
      "Chipping Sparrow                    False                        False  \n",
      "Eastern Bluebird                    False                        False  \n",
      "Grasshopper Sparrow                 False                        False  \n",
      "Field Sparrow                       False                         True  \n",
      "American Crow                       False                        False  \n"
     ]
    }
   ],
   "source": [
    "# Define the columns we need for Species_Details\n",
    "species_columns = [\n",
    "    'Common_Name', 'Scientific_Name', 'AcceptedTSN', 'TaxonCode',\n",
    "    'AOU_Code', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status'\n",
    "]\n",
    "\n",
    "# Extract relevant columns from both dataframes\n",
    "grassland_species = grassland_merged_df[species_columns].copy()\n",
    "forest_species = forest_merged_df[species_columns].copy()\n",
    "\n",
    "# Concatenate both species DataFrames\n",
    "species_combined = pd.concat([grassland_species, forest_species], ignore_index=True)\n",
    "\n",
    "# Drop duplicates to ensure unique rows per Common_Name\n",
    "species_details = species_combined.drop_duplicates(subset='Common_Name')\n",
    "\n",
    "# Set Common_Name as the index\n",
    "species_details.set_index('Common_Name', inplace=True)\n",
    "\n",
    "# Display the resulting Species_Details table\n",
    "print(species_details.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbd723",
   "metadata": {},
   "source": [
    "Now we create 2 dfs : forest_bird_observations and grassland_bird_observations with 'Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer','Visit', 'Interval_Length', 'ID_Method', 'Distance','Flyover_Observed', 'Sex', 'Common_Name', 'Temperature', 'Humidity', 'Sky', 'Wind','Disturbance', 'Initial_Three_Min_Cnt'columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2a124e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the required columns\n",
    "observation_columns = [\n",
    "    'Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
    "    'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex',\n",
    "    'Common_Name', 'Temperature', 'Humidity', 'Sky', 'Wind',\n",
    "    'Disturbance', 'Initial_Three_Min_Cnt'\n",
    "]\n",
    "\n",
    "# Create forest bird observations DataFrame\n",
    "forest_bird_observations = forest_merged_df[observation_columns].copy()\n",
    "\n",
    "# Create grassland bird observations DataFrame\n",
    "grassland_bird_observations = grassland_merged_df[observation_columns].copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9164f4",
   "metadata": {},
   "source": [
    "Now need to move data from 4 dfs namely: forest_bird_observations, grassland_bird_observations, Plot_details and species_details into 4 tables in SQL Workbench . The Plot_Name will be the primary key in Plot_details table and 'Common_Name' will be the primary key in species_details table and these 2 columns will be the foreign keys in forest_bird_observations and grassland_bird_observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a5a0f",
   "metadata": {},
   "source": [
    "pip install mysql-connector-python sqlalchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d21275",
   "metadata": {},
   "source": [
    "Create lookup tables to avoid long strings in columns 'Sky', 'Wind','Disturbance' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9dc90655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_lookup_and_merge(df1, df2, column_name):\n",
    "    # Get unique values from both DataFrames\n",
    "    combined_unique_values = pd.Series(\n",
    "        pd.concat([df1[column_name], df2[column_name]])\n",
    "        .dropna()\n",
    "        .unique()\n",
    "    ).sort_values().reset_index(drop=True)\n",
    "    \n",
    "    # Create a lookup table\n",
    "    lookup_df = pd.DataFrame({\n",
    "        f'{column_name}_Code': range(1, len(combined_unique_values) + 1),\n",
    "        column_name: combined_unique_values\n",
    "    })\n",
    "\n",
    "    # Merge with both DataFrames\n",
    "    df1 = df1.merge(lookup_df, on=column_name, how='left').drop(columns=[column_name])\n",
    "    df2 = df2.merge(lookup_df, on=column_name, how='left').drop(columns=[column_name])\n",
    "    \n",
    "    return df1, df2, lookup_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7903ad91",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sky'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\OneDrive\\Desktop\\GUVICapstoneProject2BirdsSpeciesAnalysis\\BirdSpeciesAnalysisProject\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Sky'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[121]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# For 'Sky'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m forest_bird_observations, grassland_bird_observations, sky_lookup = \u001b[43mcreate_combined_lookup_and_merge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforest_bird_observations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrassland_bird_observations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSky\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# For 'Wind'\u001b[39;00m\n\u001b[32m      6\u001b[39m forest_bird_observations, grassland_bird_observations, wind_lookup = create_combined_lookup_and_merge(\n\u001b[32m      7\u001b[39m     forest_bird_observations, grassland_bird_observations, \u001b[33m'\u001b[39m\u001b[33mWind\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[116]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mcreate_combined_lookup_and_merge\u001b[39m\u001b[34m(df1, df2, column_name)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_combined_lookup_and_merge\u001b[39m(df1, df2, column_name):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Get unique values from both DataFrames\u001b[39;00m\n\u001b[32m      3\u001b[39m     combined_unique_values = pd.Series(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         pd.concat([\u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m, df2[column_name]])\n\u001b[32m      5\u001b[39m         .dropna()\n\u001b[32m      6\u001b[39m         .unique()\n\u001b[32m      7\u001b[39m     ).sort_values().reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Create a lookup table\u001b[39;00m\n\u001b[32m     10\u001b[39m     lookup_df = pd.DataFrame({\n\u001b[32m     11\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_Code\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(combined_unique_values) + \u001b[32m1\u001b[39m),\n\u001b[32m     12\u001b[39m         column_name: combined_unique_values\n\u001b[32m     13\u001b[39m     })\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\OneDrive\\Desktop\\GUVICapstoneProject2BirdsSpeciesAnalysis\\BirdSpeciesAnalysisProject\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\OneDrive\\Desktop\\GUVICapstoneProject2BirdsSpeciesAnalysis\\BirdSpeciesAnalysisProject\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Sky'"
     ]
    }
   ],
   "source": [
    "# For 'Sky'\n",
    "forest_bird_observations, grassland_bird_observations, sky_lookup = create_combined_lookup_and_merge(\n",
    "    forest_bird_observations, grassland_bird_observations, 'Sky')\n",
    "\n",
    "# For 'Wind'\n",
    "forest_bird_observations, grassland_bird_observations, wind_lookup = create_combined_lookup_and_merge(\n",
    "    forest_bird_observations, grassland_bird_observations, 'Wind')\n",
    "\n",
    "# For 'Disturbance'\n",
    "forest_bird_observations, grassland_bird_observations, disturbance_lookup = create_combined_lookup_and_merge(\n",
    "    forest_bird_observations, grassland_bird_observations, 'Disturbance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3705c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (forest_bird_observations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d7ae1dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Plot_Name       Date Start_Time  End_Time          Observer  Visit  \\\n",
      "0  ANTI-0054 2018-05-22   05:35:00  05:45:00  Elizabeth Oswald      1   \n",
      "1  ANTI-0054 2018-05-22   05:35:00  05:45:00  Elizabeth Oswald      1   \n",
      "2  ANTI-0054 2018-05-22   05:35:00  05:45:00  Elizabeth Oswald      1   \n",
      "3  ANTI-0054 2018-05-22   05:35:00  05:45:00  Elizabeth Oswald      1   \n",
      "4  ANTI-0054 2018-05-22   05:35:00  05:45:00  Elizabeth Oswald      1   \n",
      "\n",
      "  Interval_Length ID_Method         Distance  Flyover_Observed           Sex  \\\n",
      "0       0-2.5 min   Singing  50 - 100 Meters             False          Male   \n",
      "1    7.5 - 10 min   Singing  50 - 100 Meters             False  Undetermined   \n",
      "2       0-2.5 min   Singing     <= 50 Meters             False          Male   \n",
      "3       0-2.5 min   Singing  50 - 100 Meters             False  Undetermined   \n",
      "4       0-2.5 min   Singing  50 - 100 Meters             False          Male   \n",
      "\n",
      "           Common_Name  Temperature  Humidity              Sky  \\\n",
      "0     Chipping Sparrow         20.0      79.0  Cloudy/Overcast   \n",
      "1     Eastern Bluebird         20.0      79.0  Cloudy/Overcast   \n",
      "2  Grasshopper Sparrow         20.0      79.0  Cloudy/Overcast   \n",
      "3     Eastern Bluebird         20.0      79.0  Cloudy/Overcast   \n",
      "4        Field Sparrow         20.0      79.0  Cloudy/Overcast   \n",
      "\n",
      "                                       Wind             Disturbance  \\\n",
      "0  Light breeze (4-7 mph) wind felt on face  Slight effect on count   \n",
      "1  Light breeze (4-7 mph) wind felt on face  Slight effect on count   \n",
      "2  Light breeze (4-7 mph) wind felt on face  Slight effect on count   \n",
      "3  Light breeze (4-7 mph) wind felt on face  Slight effect on count   \n",
      "4  Light breeze (4-7 mph) wind felt on face  Slight effect on count   \n",
      "\n",
      "   Initial_Three_Min_Cnt  \n",
      "0                   True  \n",
      "1                  False  \n",
      "2                   True  \n",
      "3                   True  \n",
      "4                   True  \n"
     ]
    }
   ],
   "source": [
    "print (grassland_bird_observations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96757193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define your MySQL connection string\n",
    "username = 'root'\n",
    "password = 'Raji'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database = 'your_database'\n",
    "\n",
    "# Create connection engine\n",
    "engine = create_engine(f'mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
