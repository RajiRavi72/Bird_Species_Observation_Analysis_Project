{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afb1551",
   "metadata": {},
   "source": [
    "Read the excel file Bird_Monitoring_Data_FOREST.XLSX with all the sheets into a dict using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec119db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Specify the file path\n",
    "forest_file_path = \"Bird_Monitoring_Data_FOREST.XLSX\"\n",
    "\n",
    "# Read the Excel file with multiple sheets\n",
    "forest_excel_data = pd.ExcelFile(forest_file_path)\n",
    "\n",
    "# Get all sheet names\n",
    "forest_sheet_names = forest_excel_data.sheet_names\n",
    "\n",
    "# Read data from all sheets into a dictionary\n",
    "forest_sheets_dict = {sheet: forest_excel_data.parse(sheet) for sheet in forest_sheet_names}\n",
    "forest_sheets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6bff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ANTI', 'CATO', 'CHOH', 'GWMP', 'HAFE', 'MANA', 'MONO', 'NACE', 'PRWI', 'ROCR', 'WOTR'])\n"
     ]
    }
   ],
   "source": [
    "print(forest_sheets_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa28f1",
   "metadata": {},
   "source": [
    "Now to check if all Forest Sheets have same columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3efba28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sheets have same columns\n"
     ]
    }
   ],
   "source": [
    "# Get list of all DataFrames\n",
    "dataframes = list(forest_sheets_dict.values())\n",
    "# Get column names of the first sheet\n",
    "first_columns = dataframes[0].columns\n",
    "\n",
    "# Check all others against the first\n",
    "all_same = all(df.columns.equals(first_columns) for df in dataframes)\n",
    "\n",
    "print(\"All sheets have same columns\" if all_same else \"Sheets have different columns.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a5e73f",
   "metadata": {},
   "source": [
    "We can now merge the sheets dataframes to a single dataframe called forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f0f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8546, 29)\n"
     ]
    }
   ],
   "source": [
    "forest_merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "print(forest_merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367b196",
   "metadata": {},
   "source": [
    "Now we get the raw data for Bird_Monitoring_Data_GRASSLAND.XLSX and read all sheets into a dict using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Specify the file path\n",
    "grassland_file_path = \"Bird_Monitoring_Data_GRASSLAND.XLSX\"\n",
    "\n",
    "# Read the Excel file with multiple sheets\n",
    "grassland_excel_data = pd.ExcelFile(grassland_file_path)\n",
    "\n",
    "# Get all sheet names\n",
    "grassland_sheet_names = grassland_excel_data.sheet_names\n",
    "\n",
    "# Read data from all sheets into a dictionary\n",
    "grassland_sheets_dict = {sheet: grassland_excel_data.parse(sheet) for sheet in grassland_sheet_names}\n",
    "grassland_sheets_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261c89f",
   "metadata": {},
   "source": [
    "Now we get the Sheets names from the grassland_dict key values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d07457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ANTI', 'HAFE', 'MANA', 'MONO'])\n"
     ]
    }
   ],
   "source": [
    "print(grassland_sheets_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31eb7bc",
   "metadata": {},
   "source": [
    "Now to check if all Grassland Sheets have same columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63be8d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sheets have same columns\n"
     ]
    }
   ],
   "source": [
    "# Get list of all DataFrames\n",
    "dataframes = list(grassland_sheets_dict.values())\n",
    "# Get column names of the first sheet\n",
    "first_columns = dataframes[0].columns\n",
    "\n",
    "# Check all others against the first\n",
    "all_same = all(df.columns.equals(first_columns) for df in dataframes)\n",
    "\n",
    "print(\"All sheets have same columns\" if all_same else \"Sheets have different columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d53fe5",
   "metadata": {},
   "source": [
    "We can now merge the sheets dataframes to a single dataframe called grassland_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d115051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8531, 29)\n"
     ]
    }
   ],
   "source": [
    "grassland_merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "print(grassland_merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc69ff",
   "metadata": {},
   "source": [
    "The grassland_merged_df has 8531 rows and 29 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b3f0f",
   "metadata": {},
   "source": [
    "Now we can see if we can merge forest df and grassland df into a single merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d4dda66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot merge: Columns are not the same.\n",
      "forest_merged_df columns: ['Admin_Unit_Code', 'Sub_Unit_Code', 'Site_Name', 'Plot_Name', 'Location_Type', 'Year', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit', 'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex', 'Common_Name', 'Scientific_Name', 'AcceptedTSN', 'NPSTaxonCode', 'AOU_Code', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status', 'Temperature', 'Humidity', 'Sky', 'Wind', 'Disturbance', 'Initial_Three_Min_Cnt']\n",
      "grassland_merged_df columns: ['Admin_Unit_Code', 'Sub_Unit_Code', 'Plot_Name', 'Location_Type', 'Year', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit', 'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex', 'Common_Name', 'Scientific_Name', 'AcceptedTSN', 'TaxonCode', 'AOU_Code', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status', 'Temperature', 'Humidity', 'Sky', 'Wind', 'Disturbance', 'Previously_Obs', 'Initial_Three_Min_Cnt']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Check if columns are the same\n",
    "if forest_merged_df.columns.equals(grassland_merged_df.columns):\n",
    "    # Step 2: Merge the DataFrames\n",
    "    merged_df = pd.concat([forest_merged_df, grassland_merged_df], ignore_index=True)\n",
    "    print(\"Successfully merged. Shape of merged_df:\", merged_df.shape)\n",
    "else:\n",
    "    print(\"Cannot merge: Columns are not the same.\")\n",
    "    print(\"forest_merged_df columns:\", list(forest_merged_df.columns))\n",
    "    print(\"grassland_merged_df columns:\", list(grassland_merged_df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12fa911",
   "metadata": {},
   "source": [
    "To find which columns are different in forest and grassland dfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "088157d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in forest_merged_df: {'Site_Name', 'NPSTaxonCode'}\n",
      "Only in grassland_merged_df: {'TaxonCode', 'Previously_Obs'}\n"
     ]
    }
   ],
   "source": [
    "forest_cols = set(forest_merged_df.columns)\n",
    "grassland_cols = set(grassland_merged_df.columns)\n",
    "\n",
    "print(\"Only in forest_merged_df:\", forest_cols - grassland_cols)\n",
    "print(\"Only in grassland_merged_df:\", grassland_cols - forest_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51a738",
   "metadata": {},
   "source": [
    "FOREST DATA CLEANING AND PRE PROCESSING:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4b568",
   "metadata": {},
   "source": [
    "Now we find out which columns have nulls in forest df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "840a8d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sub_Unit_Code', 'ID_Method', 'Distance', 'Sex', 'AcceptedTSN']\n"
     ]
    }
   ],
   "source": [
    "null_columns = forest_merged_df.columns[forest_merged_df.isnull().any()].tolist()\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41e655",
   "metadata": {},
   "source": [
    "So there are nulls in the above 5 columns. To find the number of nulls in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9702524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub_Unit_Code    7824\n",
      "ID_Method           1\n",
      "Distance           92\n",
      "Sex              5183\n",
      "AcceptedTSN         9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List of target columns\n",
    "columns_to_check = ['Sub_Unit_Code', 'ID_Method', 'Distance', 'Sex', 'AcceptedTSN']\n",
    "\n",
    "# Count nulls in each column\n",
    "null_counts = forest_merged_df[columns_to_check].isnull().sum()\n",
    "\n",
    "print(null_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf3389",
   "metadata": {},
   "source": [
    "Get the Admin_Unit_Code where the Sub_Unit_Code is null in forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00fe9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admin_Unit_Code values where Sub_Unit_Code is null:\n",
      "['ANTI' 'CATO' 'CHOH' 'GWMP' 'HAFE' 'MANA' 'MONO' 'PRWI' 'ROCR' 'WOTR']\n"
     ]
    }
   ],
   "source": [
    "null_admin_units = forest_merged_df[forest_merged_df['Sub_Unit_Code'].isnull()]['Admin_Unit_Code'].unique()\n",
    "print(\"Admin_Unit_Code values where Sub_Unit_Code is null:\")\n",
    "print(null_admin_units)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783f5584",
   "metadata": {},
   "source": [
    "To get the list of Admin_Unit_Codes where the Sub_Unit_Code is not null in forest df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e875e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GWMP', 'THIS'), ('NACE', 'GREE'), ('NACE', 'PISC'), ('NACE', 'FOWA'), ('NACE', 'OXHI'), ('NACE', 'ANAC'), ('NACE', 'FOCI'), ('NACE', 'FODU')]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where Sub_Unit_Code is NOT null\n",
    "filtered_df = forest_merged_df[forest_merged_df['Sub_Unit_Code'].notnull()]\n",
    "\n",
    "# Get the unique pairs of Admin_Unit_Code and Sub_Unit_Code\n",
    "admin_subunit_pairs = filtered_df[['Admin_Unit_Code', 'Sub_Unit_Code']].drop_duplicates()\n",
    "\n",
    "# Optional: convert to list of tuples\n",
    "admin_subunit_list = list(admin_subunit_pairs.itertuples(index=False, name=None))\n",
    "\n",
    "# Print result\n",
    "print(admin_subunit_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e9caed",
   "metadata": {},
   "source": [
    "Since only Admin_Unit_Code 'NACE' has Sub_Unit_Code and only one row of Admin_Unit_Code GWMP has Sub_Unit_Code we can drop Sub_Unit_Code from the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "179a2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df.drop(columns=['Sub_Unit_Code'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc1107a",
   "metadata": {},
   "source": [
    "To print the single row where  'ID_Method' is null:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf449a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_null_id = forest_merged_df[forest_merged_df['ID_Method'].isnull()]\n",
    "print(rows_with_null_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0deff7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Singing' 'Calling' 'Visualization']\n"
     ]
    }
   ],
   "source": [
    "unique_id_methods = forest_merged_df['ID_Method'].dropna().unique()\n",
    "print(unique_id_methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9044fb24",
   "metadata": {},
   "source": [
    "To get the 'Common_Name' where the ID_Method is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94f5337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Red-eyed Vireo']\n"
     ]
    }
   ],
   "source": [
    "# Get Common_Name where ID_Method is null\n",
    "common_names_with_null_id_method = forest_merged_df.loc[forest_merged_df['ID_Method'].isnull(), 'Common_Name'].unique()\n",
    "\n",
    "print(common_names_with_null_id_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd9dd9",
   "metadata": {},
   "source": [
    "To fill the ID_Method which is null with the most frequent ID_Method for the same Common_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b895af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill null ID_Method with mode for each Common_Name group\n",
    "def fill_id_method_mode(group):\n",
    "    if group['ID_Method'].isnull().any():\n",
    "        mode_value = group['ID_Method'].mode()\n",
    "        if not mode_value.empty:\n",
    "            group['ID_Method'] = group['ID_Method'].fillna(mode_value[0])\n",
    "    return group\n",
    "\n",
    "# Apply the function grouped by Common_Name\n",
    "forest_merged_df = forest_merged_df.groupby('Common_Name', group_keys=False).apply(fill_id_method_mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa798888",
   "metadata": {},
   "source": [
    "To verify if the null value is filled with default and confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98d15633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(forest_merged_df['ID_Method'].isnull().sum())  # Should print 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6f195",
   "metadata": {},
   "source": [
    "To get the unique values of the column 'Sex' in forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de97209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Sex': ['Undetermined' 'Male']\n"
     ]
    }
   ],
   "source": [
    "unique_sex_values = forest_merged_df['Sex'].dropna().unique()\n",
    "print(\"Unique values in 'Sex':\", unique_sex_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002d752",
   "metadata": {},
   "source": [
    "Unique sex values already present are 'Undetermined'and 'Male'. So the nulls can be filled with 'Undetermined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c03abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df['Sex'] = forest_merged_df['Sex'].fillna('Undetermined')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007437c2",
   "metadata": {},
   "source": [
    "To check if nulls are changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "def05de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(forest_merged_df['Sex'].isnull().sum())   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f297854",
   "metadata": {},
   "source": [
    "To get the ID_Methods where Distance is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02fc8be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_Method values where Distance is null:\n",
      "['Visualization' 'Singing' 'Calling']\n"
     ]
    }
   ],
   "source": [
    "id_methods_with_null_distance = forest_merged_df[forest_merged_df['Distance'].isnull()]['ID_Method'].unique()\n",
    "print(\"ID_Method values where Distance is null:\")\n",
    "print(id_methods_with_null_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc335b",
   "metadata": {},
   "source": [
    "To get the Common_Name of the birds where Distance is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b048a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Common_Name Distance\n",
      "47           Cedar Waxwing      NaN\n",
      "50    Red-winged Blackbird      NaN\n",
      "103           Barn Swallow      NaN\n",
      "166   Red-winged Blackbird      NaN\n",
      "322          American Crow      NaN\n",
      "...                    ...      ...\n",
      "8215         American Crow      NaN\n",
      "8239             Fish Crow      NaN\n",
      "8244         Cedar Waxwing      NaN\n",
      "8245     Unidentified Crow      NaN\n",
      "8425         American Crow      NaN\n",
      "\n",
      "[92 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(forest_merged_df[forest_merged_df['Distance'].isnull()][['Common_Name', 'Distance']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a9ea8",
   "metadata": {},
   "source": [
    "To get the count of the birds Common_Name wise where Distance is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35fc1316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Common Names with null Distance:\n",
      "Common_Name\n",
      "Common Grackle              17\n",
      "American Crow               13\n",
      "Cedar Waxwing                8\n",
      "American Goldfinch           6\n",
      "Canada Goose                 5\n",
      "Blue Jay                     5\n",
      "Great Blue Heron             4\n",
      "Mourning Dove                4\n",
      "Turkey Vulture               4\n",
      "Chimney Swift                3\n",
      "Unidentified Crow            3\n",
      "Fish Crow                    3\n",
      "American Robin               2\n",
      "Red-winged Blackbird         2\n",
      "Barn Swallow                 2\n",
      "Double-crested Cormorant     2\n",
      "European Starling            2\n",
      "Red-shouldered Hawk          2\n",
      "Wood Duck                    1\n",
      "Mallard                      1\n",
      "Green Heron                  1\n",
      "Peregrine Falcon             1\n",
      "Pileated Woodpecker          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "common_name_null_distance_counts = (\n",
    "    forest_merged_df[forest_merged_df['Distance'].isnull()]\n",
    "    ['Common_Name']\n",
    "    .value_counts(dropna=True)\n",
    ")\n",
    "\n",
    "print(\"Count of Common Names with null Distance:\")\n",
    "print(common_name_null_distance_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305812a0",
   "metadata": {},
   "source": [
    "There are 92 nulls in Distance column. Fill the nulls in Distance with the most frequent Distance for that particular Common_Name of the species in that particular Plot_Name :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to fill null Distance with the mode within each Plot_Name + Common_Name group\n",
    "def fill_distance_with_mode_by_group(group):\n",
    "    if group['Distance'].isnull().any():\n",
    "        mode_val = group['Distance'].mode()\n",
    "        if not mode_val.empty:\n",
    "            group['Distance'] = group['Distance'].fillna(mode_val[0])\n",
    "    return group\n",
    "\n",
    "# Apply group-wise operation\n",
    "forest_merged_df = (\n",
    "    forest_merged_df\n",
    "    .groupby(['Plot_Name', 'Common_Name'], group_keys=False)\n",
    "    .apply(fill_distance_with_mode_by_group)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b0eff",
   "metadata": {},
   "source": [
    "To check if the nulls were updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89ff82aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining nulls in Distance column: 57\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining nulls in Distance column:\", forest_merged_df['Distance'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94232c93",
   "metadata": {},
   "source": [
    "There are still 57 nulls in Distance column. Fill the nulls in Distance with the most frequent Distance for that particular Common_Name of the species in that particular Admin_Unit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to fill null Distance with the mode within each Admin_Unit_Code + Common_Name group\n",
    "def fill_distance_with_mode_by_group(group):\n",
    "    if group['Distance'].isnull().any():\n",
    "        mode_val = group['Distance'].mode()\n",
    "        if not mode_val.empty:\n",
    "            group['Distance'] = group['Distance'].fillna(mode_val[0])\n",
    "    return group\n",
    "\n",
    "# Apply group-wise operation\n",
    "forest_merged_df = (\n",
    "    forest_merged_df\n",
    "    .groupby(['Admin_Unit_Code', 'Common_Name'], group_keys=False)\n",
    "    .apply(fill_distance_with_mode_by_group)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "251c6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining nulls in Distance column: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining nulls in Distance column:\", forest_merged_df['Distance'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18616b",
   "metadata": {},
   "source": [
    "There are still 10 rows with nulls in Distance because the most frequent value of Distance for these Common_Name in the particular Admin_Unit_Code is itself null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d64e20ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common_Name values with unfilled nulls in Distance:\n",
      "['Barn Swallow' 'Peregrine Falcon' 'Turkey Vulture' 'Chimney Swift'\n",
      " 'Canada Goose' 'Fish Crow' 'Unidentified Crow']\n"
     ]
    }
   ],
   "source": [
    "# Find Common_Name groups where Distance is still null\n",
    "unfilled_common_names = (\n",
    "    forest_merged_df[forest_merged_df['Distance'].isnull()]\n",
    "    ['Common_Name']\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "print(\"Common_Name values with unfilled nulls in Distance:\")\n",
    "print(unfilled_common_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3089f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Common_Name  Null_Distance_Count\n",
      "5     Turkey Vulture                    3\n",
      "0       Barn Swallow                    2\n",
      "1       Canada Goose                    1\n",
      "2      Chimney Swift                    1\n",
      "3          Fish Crow                    1\n",
      "4   Peregrine Falcon                    1\n",
      "6  Unidentified Crow                    1\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where Distance is still null\n",
    "null_distance_df = forest_merged_df[forest_merged_df['Distance'].isnull()]\n",
    "\n",
    "# Group by Common_Name and count how many such rows exist\n",
    "unfilled_counts = null_distance_df.groupby('Common_Name').size().reset_index(name='Null_Distance_Count')\n",
    "\n",
    "# Sort descending by count\n",
    "unfilled_counts = unfilled_counts.sort_values(by='Null_Distance_Count', ascending=False)\n",
    "\n",
    "print(unfilled_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac9c05",
   "metadata": {},
   "source": [
    "So from above, we see only 10 rows exists, where the Distance is null because there are no rows with no nulls for these types of birds in that particular Admin_Unit. We can assume the most frequent distance of the entire Admin_Unit in these cases and fill with that value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b60b1d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null Distance values: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Step 3: Find Admin_Unit_Code groups where Distance is still null\n",
    "still_null = forest_merged_df[forest_merged_df['Distance'].isnull()]\n",
    "\n",
    "#  For each Admin_Unit_Code with remaining nulls, fill those nulls with mode Distance of entire Admin_Unit_Code\n",
    "for admin_unit in still_null['Admin_Unit_Code'].unique():\n",
    "    # Calculate mode of Distance for this Admin_Unit_Code (excluding nulls)\n",
    "    admin_mode = forest_merged_df.loc[\n",
    "        (forest_merged_df['Admin_Unit_Code'] == admin_unit) & \n",
    "        (forest_merged_df['Distance'].notnull()), 'Distance'\n",
    "    ].mode()\n",
    "    \n",
    "    if not admin_mode.empty:\n",
    "        # Fill null Distance for this Admin_Unit_Code with its mode\n",
    "        forest_merged_df.loc[\n",
    "            (forest_merged_df['Admin_Unit_Code'] == admin_unit) & \n",
    "            (forest_merged_df['Distance'].isnull()), 'Distance'\n",
    "        ] = admin_mode[0]\n",
    "\n",
    "\n",
    "# Confirm no nulls remain\n",
    "print(\"Remaining null Distance values:\", forest_merged_df['Distance'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b28b2",
   "metadata": {},
   "source": [
    "List unique 'AccceptedTSN' values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db21ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in AcceptedTSN:\n",
      "[179276. 178775. 178195. 179064. 178620. 179124. 554256. 177125. 179443.\n",
      " 178581. 554383. 178359. 179731. 179150. 554138. 950039. 179801. 178259.\n",
      " 179435. 179083. 178309. 179853. 178532. 179680. 179236. 179045. 178166.\n",
      " 179112. 179021. 553526. 178339. 178262. 179009. 179492. 179333. 178448.\n",
      " 179777. 179759. 178329.     nan 177831. 179104. 179883. 178279. 950033.\n",
      " 176136. 950029. 178927. 178154. 178979. 179788. 950009. 178844. 178850.\n",
      " 178541. 950079. 178627. 178625. 178944. 950041. 179737. 175122. 174793.\n",
      " 178119. 950049. 179023. 175359. 554382. 950010. 174999. 950042. 174773.\n",
      " 177921. 178991. 950045. 179488. 174717. 179724. 175063. 178443. 178032.\n",
      " 178001. 178937. 175590. 175272. 178964. 950011. 179637. 179628. 179410.\n",
      " 175265. 175604. 179034. 179796. 950052. 950036. 950061. 847323. 950031.\n",
      " 950046. 950035. 179888. 176520. 178277. 950106. 950097. 178186. 175350.]\n"
     ]
    }
   ],
   "source": [
    "unique_accepted_tsn = forest_merged_df['AcceptedTSN'].unique()\n",
    "print(\"Unique values in AcceptedTSN:\")\n",
    "print(unique_accepted_tsn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ee6f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from Common_Name to its most frequent non-null AcceptedTSN\n",
    "accepted_tsn_map = (\n",
    "    forest_merged_df[forest_merged_df['AcceptedTSN'].notnull()]\n",
    "    .groupby('Common_Name')['AcceptedTSN']\n",
    "    .agg(lambda x: x.mode().iloc[0])  # pick the most frequent AcceptedTSN if multiple\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Function to fill AcceptedTSN from mapping\n",
    "def fill_accepted_tsn(row):\n",
    "    if pd.isnull(row['AcceptedTSN']):\n",
    "        return accepted_tsn_map.get(row['Common_Name'], row['AcceptedTSN'])\n",
    "    else:\n",
    "        return row['AcceptedTSN']\n",
    "\n",
    "# Apply the function row-wise\n",
    "forest_merged_df['AcceptedTSN'] = forest_merged_df.apply(fill_accepted_tsn, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39613995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining nulls in AcceptedTSN: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining nulls in AcceptedTSN:\", forest_merged_df['AcceptedTSN'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70c89e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Common_Name  AcceptedTSN  Filled_AcceptedTSN\n",
      "165   House Finch          NaN                 NaN\n",
      "635   House Finch          NaN                 NaN\n",
      "638   House Finch          NaN                 NaN\n",
      "1337  House Finch          NaN                 NaN\n",
      "3708  House Finch          NaN                 NaN\n",
      "3912  House Finch          NaN                 NaN\n",
      "3920  House Finch          NaN                 NaN\n",
      "3921  House Finch          NaN                 NaN\n",
      "4034  House Finch          NaN                 NaN\n"
     ]
    }
   ],
   "source": [
    "# First, create a mapping from Common_Name to the most frequent non-null AcceptedTSN\n",
    "accepted_tsn_map = (\n",
    "    forest_merged_df[forest_merged_df['AcceptedTSN'].notnull()]\n",
    "    .groupby('Common_Name')['AcceptedTSN']\n",
    "    .agg(lambda x: x.mode().iloc[0])  # most frequent AcceptedTSN per Common_Name\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Now, filter rows where AcceptedTSN is null\n",
    "null_accepted_tsn_rows = forest_merged_df[forest_merged_df['AcceptedTSN'].isnull()]\n",
    "\n",
    "# For each such row, get the AcceptedTSN from the mapping\n",
    "null_accepted_tsn_rows = null_accepted_tsn_rows.copy()  # avoid SettingWithCopyWarning\n",
    "null_accepted_tsn_rows['Filled_AcceptedTSN'] = null_accepted_tsn_rows['Common_Name'].map(accepted_tsn_map)\n",
    "\n",
    "# Show the results: Common_Name, current null AcceptedTSN, and the mapped AcceptedTSN to fill\n",
    "print(null_accepted_tsn_rows[['Common_Name', 'AcceptedTSN', 'Filled_AcceptedTSN']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743bb0d",
   "metadata": {},
   "source": [
    "Now we can fill the AcceptedTSN for House Finch which are nulls as 'Unknown':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37dbd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df['AcceptedTSN'] = forest_merged_df['AcceptedTSN'].fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55f8c8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[179276.0 178775.0 178195.0 179064.0 178620.0 179124.0 554256.0 177125.0\n",
      " 179443.0 178581.0 554383.0 178359.0 179731.0 179150.0 554138.0 950039.0\n",
      " 179801.0 178259.0 179435.0 179083.0 178309.0 179853.0 178532.0 179680.0\n",
      " 179236.0 179045.0 178166.0 179112.0 179021.0 553526.0 178339.0 178262.0\n",
      " 179009.0 179492.0 179333.0 178448.0 179777.0 179759.0 178329.0 'Unknown'\n",
      " 177831.0 179104.0 179883.0 178279.0 950033.0 176136.0 950029.0 178927.0\n",
      " 178154.0 178979.0 179788.0 950009.0 178844.0 178850.0 178541.0 950079.0\n",
      " 178627.0 178625.0 178944.0 950041.0 179737.0 175122.0 174793.0 178119.0\n",
      " 950049.0 179023.0 175359.0 554382.0 950010.0 174999.0 950042.0 174773.0\n",
      " 177921.0 178991.0 950045.0 179488.0 174717.0 179724.0 175063.0 178443.0\n",
      " 178032.0 178001.0 178937.0 175590.0 175272.0 178964.0 950011.0 179637.0\n",
      " 179628.0 179410.0 175265.0 175604.0 179034.0 179796.0 950052.0 950036.0\n",
      " 950061.0 847323.0 950031.0 950046.0 950035.0 179888.0 176520.0 178277.0\n",
      " 950106.0 950097.0 178186.0 175350.0]\n"
     ]
    }
   ],
   "source": [
    "print(forest_merged_df['AcceptedTSN'].isnull().sum())  # Should return 0\n",
    "print(forest_merged_df['AcceptedTSN'].unique())        # To verify 'Unknown' is included\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3a70e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ The DataFrame has no null values.\n"
     ]
    }
   ],
   "source": [
    "# Returns True if any nulls exist, else False\n",
    "has_nulls = forest_merged_df.isnull().values.any()\n",
    "\n",
    "if has_nulls:\n",
    "    print(\"There are still null values in the DataFrame.\")\n",
    "    # Optional: show which columns have nulls\n",
    "    print(forest_merged_df.isnull().sum())\n",
    "else:\n",
    "    print(\"✅ The DataFrame has no null values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af201cef",
   "metadata": {},
   "source": [
    "To check if any duplicates in forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a324ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 duplicate rows in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Count total number of duplicate rows\n",
    "duplicate_count = forest_merged_df.duplicated().sum()\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(f\"There are {duplicate_count} duplicate rows in the DataFrame.\")\n",
    "else:\n",
    "    print(\"✅ No duplicate rows found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbd712",
   "metadata": {},
   "source": [
    "To print the original + duplicates in forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will include both the original and its duplicates\n",
    "duplicates_all = forest_merged_df[forest_merged_df.duplicated(keep=False)]\n",
    "print(duplicates_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d2657",
   "metadata": {},
   "source": [
    "Now we can drop the duplicates and keep the first instance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2bab966",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df = forest_merged_df.drop_duplicates(keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da9a9d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Remaining duplicates: {forest_merged_df.duplicated().sum()}\")  # Should be 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2eb5c2",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the Scientific_Name should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11e295a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single Scientific_Name.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique Scientific_Name entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['Scientific_Name'].nunique()\n",
    "\n",
    "# Find where more than one Scientific_Name exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ Scientific_Name mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single Scientific_Name.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f3e87",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the AcceptedTSN should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07eeea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single AcceptedTSN.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique AcceptedTSN entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['AcceptedTSN'].nunique()\n",
    "\n",
    "# Find where more than one AcceptedTSN exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ AcceptedTSN mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single AcceptedTSN.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fbaa1",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the NPSTaxonCode should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf8fa14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single NPSTaxonCode.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique NPSTaxonCode entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['NPSTaxonCode'].nunique()\n",
    "\n",
    "# Find where more than one NPSTaxonCode exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ NPSTaxonCode mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single NPSTaxonCode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22399487",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the AOU_Code should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8256dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single AOU_Code.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique AOU_Code entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['AOU_Code'].nunique()\n",
    "\n",
    "# Find where more than one AOU_Code exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ AOU_Code mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single AOU_Code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd2755",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the PIF_Watchlist_Status should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff6919a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single PIF_Watchlist_Status.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique PIF_Watchlist_Status entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['PIF_Watchlist_Status'].nunique()\n",
    "\n",
    "# Find where more than one PIF_Watchlist_Status exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ PIF_Watchlist_Status mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single PIF_Watchlist_Status.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5d603",
   "metadata": {},
   "source": [
    "Now to check Consisitency of data: For every Common_Name the Regional_Stewardship_Status should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "895e2960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Common_Name maps to a single Regional_Stewardship_Status.\n"
     ]
    }
   ],
   "source": [
    "# Group by Common_Name and count unique Regional_Stewardship_Status entries\n",
    "name_check = forest_merged_df.groupby('Common_Name')['Regional_Stewardship_Status'].nunique()\n",
    "\n",
    "# Find where more than one Regional_Stewardship_Status exists for a Common_Name\n",
    "inconsistent_names = name_check[name_check > 1]\n",
    "\n",
    "# Show inconsistent mappings\n",
    "if not inconsistent_names.empty:\n",
    "    print(\"❌ Inconsistent Common_Name ↔ Regional_Stewardship_Status mappings found:\")\n",
    "    print(inconsistent_names)\n",
    "else:\n",
    "    print(\"✅ Each Common_Name maps to a single Regional_Stewardship_Status.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a1f7a",
   "metadata": {},
   "source": [
    "Findings: Fron the above we find that for every Common_Name there is a single Scientific_Name, AcceptedTSN, NPSTaxonCode, AOU_Code, PIF_Watchlist_Status, and Regional_Stewardship_Status. So these columns can be combined togoether in a table indexed on the Common_Name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a55ab",
   "metadata": {},
   "source": [
    "To check if each unique Plot_Name always maps to the same Admin_Unit_Code and Site_Name in forest_merged_df, we can group by Plot_Name and count unique values in the other two columns and find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a837edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Each Plot_Name has consistent Admin_Unit_Code and Site_Name.\n"
     ]
    }
   ],
   "source": [
    "# Group by Plot_Name and count unique Admin_Unit_Code and Site_Name\n",
    "consistency_check = forest_merged_df.groupby('Plot_Name')[['Admin_Unit_Code', 'Site_Name']].nunique()\n",
    "\n",
    "# Find Plot_Names with more than one unique value in either column\n",
    "inconsistent_plots = consistency_check[(consistency_check['Admin_Unit_Code'] > 1) | \n",
    "                                       (consistency_check['Site_Name'] > 1)] \n",
    "\n",
    "# Output the inconsistencies\n",
    "if not inconsistent_plots.empty:\n",
    "    print(\"❌ Inconsistencies found for the following Plot_Name(s):\")\n",
    "    print(inconsistent_plots)\n",
    "else:\n",
    "    print(\"✅ Each Plot_Name has consistent Admin_Unit_Code and Site_Name.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614a24b",
   "metadata": {},
   "source": [
    "Findings: Fron the above we find that for every Plot_Name there is a single Admin_Unit_Code and Site_Name. So these columns can be combined togoether in a table indexed on the Plot_Name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca81962",
   "metadata": {},
   "source": [
    "Now to analyse the data types of the columns in forest_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e28d654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Admin_Unit_Code                        object\n",
       "Site_Name                              object\n",
       "Plot_Name                              object\n",
       "Location_Type                          object\n",
       "Year                                    int64\n",
       "Date                           datetime64[ns]\n",
       "Start_Time                             object\n",
       "End_Time                               object\n",
       "Observer                               object\n",
       "Visit                                   int64\n",
       "Interval_Length                        object\n",
       "ID_Method                              object\n",
       "Distance                               object\n",
       "Flyover_Observed                         bool\n",
       "Sex                                    object\n",
       "Common_Name                            object\n",
       "Scientific_Name                        object\n",
       "AcceptedTSN                            object\n",
       "NPSTaxonCode                            int64\n",
       "AOU_Code                               object\n",
       "PIF_Watchlist_Status                     bool\n",
       "Regional_Stewardship_Status              bool\n",
       "Temperature                           float64\n",
       "Humidity                              float64\n",
       "Sky                                    object\n",
       "Wind                                   object\n",
       "Disturbance                            object\n",
       "Initial_Three_Min_Cnt                    bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_merged_df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99d4aa",
   "metadata": {},
   "source": [
    "Now the Start_Time and End_Time are in object format (string) which needs to be converted and only Time should be present :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "034c8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df['Start_Time'] = pd.to_datetime(forest_merged_df['Start_Time'], format='%H:%M:%S', errors='coerce').dt.time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146db975",
   "metadata": {},
   "source": [
    "To confirm if the Start_Time is of correct class datetime.time :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f640a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'datetime.time'>], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_merged_df['Start_Time'].apply(type).unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da43654",
   "metadata": {},
   "source": [
    "Now check for End_Time and do the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b74f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df['End_Time'] = pd.to_datetime(forest_merged_df['End_Time'], format='%H:%M:%S', errors='coerce').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83b9a4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'datetime.time'>], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_merged_df['Start_Time'].apply(type).unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74b188",
   "metadata": {},
   "source": [
    "GRASSLAND DATA CLEANING AND PRE PROCESSING:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e609b76",
   "metadata": {},
   "source": [
    "To list down the columns with nulls in Grassland df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24ba1ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sub_Unit_Code', 'ID_Method', 'Distance', 'AcceptedTSN', 'TaxonCode']\n"
     ]
    }
   ],
   "source": [
    "null_columns = grassland_merged_df.columns[grassland_merged_df.isnull().any()].tolist()\n",
    "print(null_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd2ca3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3bbb45cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub_Unit_Code    8531\n",
      "ID_Method           1\n",
      "Distance         1394\n",
      "AcceptedTSN        24\n",
      "TaxonCode           2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List of target columns\n",
    "columns_to_check = ['Sub_Unit_Code', 'ID_Method', 'Distance', 'AcceptedTSN', 'TaxonCode']\n",
    "\n",
    "# Count nulls in each column\n",
    "null_counts = grassland_merged_df[columns_to_check].isnull().sum()\n",
    "\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ea35add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grassland_merged_df['Sub_Unit_Code'].dropna().unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd9fc5",
   "metadata": {},
   "source": [
    "The Sub_Unit_Code is entire column with nulls in grassland_merged_df and the column can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e967ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df.drop(columns=['Sub_Unit_Code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b60102",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9fdfec",
   "metadata": {},
   "source": [
    "To print the single row where  'ID_Method' is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_null_id = grassland_merged_df[grassland_merged_df['ID_Method'].isnull()]\n",
    "print(rows_with_null_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7447de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Singing' 'Calling' 'Visualization']\n"
     ]
    }
   ],
   "source": [
    "unique_id_methods = grassland_merged_df['ID_Method'].dropna().unique()\n",
    "print(unique_id_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895e7bf",
   "metadata": {},
   "source": [
    "Get Common_Name where ID_Method is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00e8bd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['American Crow']\n"
     ]
    }
   ],
   "source": [
    "common_names_with_null_id_method = grassland_merged_df.loc[grassland_merged_df['ID_Method'].isnull(), 'Common_Name'].unique()\n",
    "print(common_names_with_null_id_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0d8f4a",
   "metadata": {},
   "source": [
    "To fill the ID_Method which is null with the most frequent ID_Method for the same Common_Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill null ID_Method with mode for each Common_Name group\n",
    "def fill_id_method_mode(group):\n",
    "    if group['ID_Method'].isnull().any():\n",
    "        mode_value = group['ID_Method'].mode()\n",
    "        if not mode_value.empty:\n",
    "            group['ID_Method'] = group['ID_Method'].fillna(mode_value[0])\n",
    "    return group\n",
    "\n",
    "# Apply the function grouped by Common_Name\n",
    "grassland_merged_df = grassland_merged_df.groupby('Common_Name', group_keys=False).apply(fill_id_method_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625826e",
   "metadata": {},
   "source": [
    "To verify if the null value is filled and confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd78927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(grassland_merged_df['ID_Method'].isnull().sum())  # Should print 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b970d61",
   "metadata": {},
   "source": [
    "To get the Distance which are null Common_Name wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8453bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Common Names with null Distance:\n",
      "Common_Name\n",
      "European Starling                321\n",
      "Cedar Waxwing                    255\n",
      "Common Grackle                   127\n",
      "Barn Swallow                     127\n",
      "American Goldfinch               101\n",
      "Red-winged Blackbird              83\n",
      "Mourning Dove                     52\n",
      "Turkey Vulture                    44\n",
      "Brown-headed Cowbird              34\n",
      "American Crow                     32\n",
      "Tree Swallow                      29\n",
      "Blue Jay                          20\n",
      "American Robin                    20\n",
      "Northern Rough-winged Swallow     16\n",
      "Unidentified Crow                 14\n",
      "Canada Goose                      14\n",
      "Great Blue Heron                  12\n",
      "Unidentified Swallow              11\n",
      "Rock Dove                         11\n",
      "Fish Crow                         10\n",
      "Killdeer                           7\n",
      "Northern Cardinal                  6\n",
      "Bald Eagle                         5\n",
      "House Finch                        5\n",
      "American Kestrel                   5\n",
      "Chimney Swift                      4\n",
      "Purple Martin                      3\n",
      "Eastern Bluebird                   3\n",
      "Eastern Kingbird                   3\n",
      "Indigo Bunting                     3\n",
      "Northern Mockingbird               3\n",
      "Red-tailed Hawk                    2\n",
      "Black Vulture                      2\n",
      "Eastern Meadowlark                 2\n",
      "Baltimore Oriole                   2\n",
      "Wood Duck                          1\n",
      "Ruby-throated Hummingbird          1\n",
      "Red-shouldered Hawk                1\n",
      "Gray Catbird                       1\n",
      "Pileated Woodpecker                1\n",
      "Red-bellied Woodpecker             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "common_name_null_distance_counts = (\n",
    "    grassland_merged_df[grassland_merged_df['Distance'].isnull()]\n",
    "    ['Common_Name']\n",
    "    .value_counts(dropna=True)\n",
    ")\n",
    "print(\"Count of Common Names with null Distance:\")\n",
    "print(common_name_null_distance_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71840fa2",
   "metadata": {},
   "source": [
    "There are 1394 nulls in Distance Column. Fill the nulls in Distance with the most frequent Distance for that particular Common_Name of the species in that particular Plot_Name :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to fill null Distance with the mode within each Plot_Name + Common_Name group\n",
    "def fill_distance_with_mode_by_group(group):\n",
    "    if group['Distance'].isnull().any():\n",
    "        mode_val = group['Distance'].mode()\n",
    "        if not mode_val.empty:\n",
    "            group['Distance'] = group['Distance'].fillna(mode_val[0])\n",
    "    return group\n",
    "\n",
    "# Apply group-wise operation\n",
    "grassland_merged_df = (\n",
    "    grassland_merged_df\n",
    "    .groupby(['Plot_Name', 'Common_Name'], group_keys=False)\n",
    "    .apply(fill_distance_with_mode_by_group)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed9b34",
   "metadata": {},
   "source": [
    "To check if the nulls were updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b41cda79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining nulls in Distance column: 748\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining nulls in Distance column:\", grassland_merged_df['Distance'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbedeab",
   "metadata": {},
   "source": [
    "There are still 748 rows with nulls in Distance because the most frequent value of Distance for these Common_Name in the particular Plot_Name is itself null. Now fill the nulls in Distance with the most frequent Distance for that particular Common_Name of the species in that particular Admin_Unit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921eb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to fill null Distance with the mode within each Admin_Unit_Code + Common_Name group\n",
    "def fill_distance_with_mode_by_group(group):\n",
    "    if group['Distance'].isnull().any():\n",
    "        mode_val = group['Distance'].mode()\n",
    "        if not mode_val.empty:\n",
    "            group['Distance'] = group['Distance'].fillna(mode_val[0])\n",
    "    return group\n",
    "\n",
    "# Apply group-wise operation\n",
    "grassland_merged_df = (\n",
    "    grassland_merged_df\n",
    "    .groupby(['Admin_Unit_Code', 'Common_Name'], group_keys=False)\n",
    "    .apply(fill_distance_with_mode_by_group)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd675975",
   "metadata": {},
   "source": [
    "To check if the nulls were updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfc28ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining nulls in Distance column: 49\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining nulls in Distance column:\", grassland_merged_df['Distance'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ea629",
   "metadata": {},
   "source": [
    "There are still 49 rows with nulls in Distance because the most frequent value of Distance for these Common_Name in the particular Admin_Unit_Code is itself null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b7c68cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common_Name values with unfilled nulls in Distance:\n",
      "['Bald Eagle' 'Wood Duck' 'Unidentified Crow' 'Canada Goose'\n",
      " 'Great Blue Heron' 'Purple Martin' 'Unidentified Swallow' 'Black Vulture'\n",
      " 'American Kestrel']\n"
     ]
    }
   ],
   "source": [
    "# Find Common_Name groups where Distance is still null\n",
    "unfilled_common_names = (\n",
    "    grassland_merged_df[grassland_merged_df['Distance'].isnull()]\n",
    "    ['Common_Name']\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "print(\"Common_Name values with unfilled nulls in Distance:\")\n",
    "print(unfilled_common_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "acf509f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Common_Name  Null_Distance_Count\n",
      "4      Great Blue Heron                   12\n",
      "7  Unidentified Swallow                   11\n",
      "6     Unidentified Crow                    7\n",
      "3          Canada Goose                    6\n",
      "1            Bald Eagle                    5\n",
      "0      American Kestrel                    3\n",
      "5         Purple Martin                    3\n",
      "2         Black Vulture                    1\n",
      "8             Wood Duck                    1\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where Distance is still null\n",
    "null_distance_df = grassland_merged_df[grassland_merged_df['Distance'].isnull()]\n",
    "\n",
    "# Group by Common_Name and count how many such rows exist\n",
    "unfilled_counts = null_distance_df.groupby('Common_Name').size().reset_index(name='Null_Distance_Count')\n",
    "\n",
    "# Sort descending by count\n",
    "unfilled_counts = unfilled_counts.sort_values(by='Null_Distance_Count', ascending=False)\n",
    "\n",
    "print(unfilled_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48785b",
   "metadata": {},
   "source": [
    "So from above, we see only 49 rows exists, where the Distance is null because there are no rows with no nulls for these types of birds in that particular Admin_Unit. \n",
    "We can assume the most frequent distance of the entire Admin_Unit in these cases and fill with that value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e5c9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Find Admin_Unit_Code groups where Distance is still null\n",
    "still_null = grassland_merged_df[grassland_merged_df['Distance'].isnull()]\n",
    "\n",
    "#  For each Admin_Unit_Code with remaining nulls, fill those nulls with mode Distance of entire Admin_Unit_Code\n",
    "for admin_unit in still_null['Admin_Unit_Code'].unique():\n",
    "    # Calculate mode of Distance for this Admin_Unit_Code (excluding nulls)\n",
    "    admin_mode = grassland_merged_df.loc[\n",
    "        (grassland_merged_df['Admin_Unit_Code'] == admin_unit) & \n",
    "        (grassland_merged_df['Distance'].notnull()), 'Distance'\n",
    "    ].mode()\n",
    "    \n",
    "    if not admin_mode.empty:\n",
    "        # Fill null Distance for this Admin_Unit_Code with its mode\n",
    "        grassland_merged_df.loc[\n",
    "            (grassland_merged_df['Admin_Unit_Code'] == admin_unit) & \n",
    "            (grassland_merged_df['Distance'].isnull()), 'Distance'\n",
    "        ] = admin_mode[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e974d",
   "metadata": {},
   "source": [
    " Confirm no nulls remain in Distance in grassland df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ae853134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null Distance values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining null Distance values:\", grassland_merged_df['Distance'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635dc66",
   "metadata": {},
   "source": [
    "List unique 'AccceptedTSN' values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d4556d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in AcceptedTSN:\n",
      "[179435. 179801. 179333. 179443. 179731. 178279. 179150. 179124. 177125.\n",
      " 179276. 179492. 178431. 178581. 950041. 179112. 179083. 179737. 178309.\n",
      " 179759. 175265. 178195. 554138. 174999. 179680. 554383. 178625. 179777.\n",
      " 179724. 554256. 178359. 179064. 178532. 178944. 179853. 178339. 178620.\n",
      " 179104. 175420. 179045. 179034. 178448. 179366. 179236. 178627. 178329.\n",
      " 553526. 178541. 178262. 179023. 178001. 175272. 179637.     nan 178154.\n",
      " 179021. 175350. 176520. 175622. 179883. 950033. 178775. 178979. 179145.\n",
      " 177831. 178259. 950045. 175122. 178166. 179628. 175359. 950052. 178964.\n",
      " 175309. 178032. 177071. 179736. 178443. 179009. 179796. 174773. 176136.\n",
      " 179888. 178991. 178341. 178927. 950035. 179788. 178464. 179314. 178423.\n",
      " 174861. 950040. 179032. 950039. 178277. 178937. 178119. 178842. 950010.\n",
      " 950061. 178844. 179462. 177921. 179488. 950036. 950031. 178344.]\n"
     ]
    }
   ],
   "source": [
    "unique_accepted_tsn = grassland_merged_df['AcceptedTSN'].unique()\n",
    "print(\"Unique values in AcceptedTSN:\")\n",
    "print(unique_accepted_tsn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf88ed",
   "metadata": {},
   "source": [
    "Check if AcceptedTSN value exists in any other row for the same Common_Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef48f172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Common_Name, AcceptedTSN]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get Common_Name values where AcceptedTSN is null\n",
    "common_names_with_null_acceptedtsn = grassland_merged_df.loc[grassland_merged_df['AcceptedTSN'].isna(), 'Common_Name'].unique()\n",
    "\n",
    "# Step 2: Filter rows with those Common_Names and where AcceptedTSN is NOT null\n",
    "rows_with_taxoncode = grassland_merged_df[\n",
    "    (grassland_merged_df['Common_Name'].isin(common_names_with_null_acceptedtsn)) &\n",
    "    (grassland_merged_df['AcceptedTSN'].notna())\n",
    "]\n",
    "\n",
    "# Step 3: See if any AcceptedTSN exists for those Common_Names\n",
    "print(rows_with_taxoncode[['Common_Name', 'AcceptedTSN']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097f780",
   "metadata": {},
   "source": [
    "To fill all nulls in AcceptedTSN with 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc1772c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df['AcceptedTSN'] = grassland_merged_df['AcceptedTSN'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e091c",
   "metadata": {},
   "source": [
    "To check TaxonCode for nulls: List unique TaxonCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b108a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in TaxonCode:\n",
      "[ 84781.  87184.  83867.  84790.  87106.  85757.  94257.  94228.  82737.\n",
      "  83803.  85643.  87391.  88350. 773819.  94215.  93655.  87112.  85791.\n",
      "  87136.  79468.  84865. 266957.  76625.  86252. 265876.  89977.  87156.\n",
      "  87098. 264079.  85846.  93634.  88296.  92708.  88038.  85824.  88394.\n",
      "  94206.  80444.  93613.  93601.  87409.  84704.  95286.  89979.  85813.\n",
      " 263793.  88306.  85739.  93589.  83046.  79476.  86204. 926917.  84820.\n",
      "  93587.  79563.  77646.  82543.  88071. 890949.  90935.  92746.  94251.\n",
      "  89102.  84936. 890952.  77836.  84833.  86194.  79572. 890945.  92730.\n",
      "  79517.  83884.  82677.     nan  87404.  93573.  87177.  84416.  86451.\n",
      "  88076.  93552.  85827.  92689. 774021.  87168.  87427.  83846.  87382.\n",
      " 773820.  93599. 773778.  85755.  92700.  83980.  91010. 773765. 890946.\n",
      "  91012.  85610.  82956.  85638. 890943. 773818.  85830.]\n"
     ]
    }
   ],
   "source": [
    "unique_taxoncode = grassland_merged_df['TaxonCode'].unique()\n",
    "print(\"Unique values in TaxonCode:\")\n",
    "print(unique_taxoncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4bfd5544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2596     Northwestern Crow\n",
      "5556    Chinese Pond-Heron\n",
      "Name: Common_Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where TaxonCode is null and get the corresponding Common_Name\n",
    "null_taxoncode_common_names = grassland_merged_df.loc[grassland_merged_df['TaxonCode'].isna(), 'Common_Name']\n",
    "print(null_taxoncode_common_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a74999fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Common_Name, TaxonCode]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get Common_Name values where TaxonCode is null\n",
    "common_names_with_null_taxoncode = grassland_merged_df.loc[grassland_merged_df['TaxonCode'].isna(), 'Common_Name'].unique()\n",
    "\n",
    "# Step 2: Filter rows with those Common_Names and where TaxonCode is NOT null\n",
    "rows_with_taxoncode = grassland_merged_df[\n",
    "    (grassland_merged_df['Common_Name'].isin(common_names_with_null_taxoncode)) &\n",
    "    (grassland_merged_df['TaxonCode'].notna())\n",
    "]\n",
    "\n",
    "# Step 3: See if any TaxonCode exists for those Common_Names\n",
    "print(rows_with_taxoncode[['Common_Name', 'TaxonCode']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c681b",
   "metadata": {},
   "source": [
    "Fill TaxonCode with nulls as 'Unknown' in grassland_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc50b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df['TaxonCode'] = grassland_merged_df['TaxonCode'].fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "583e601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ The DataFrame has no null values.\n"
     ]
    }
   ],
   "source": [
    "# Returns True if any nulls exist, else False\n",
    "has_nulls = grassland_merged_df.isnull().values.any()\n",
    "\n",
    "if has_nulls:\n",
    "    print(\"There are still null values in the DataFrame.\")\n",
    "    # Optional: show which columns have nulls\n",
    "    print(grassland_merged_df.isnull().sum())\n",
    "else:\n",
    "    print(\"✅ The DataFrame has no null values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88697b78",
   "metadata": {},
   "source": [
    "To check if any duplicates in grassland_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "acd21ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1705 duplicate rows in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Count total number of duplicate rows\n",
    "duplicate_count = grassland_merged_df.duplicated().sum()\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(f\"There are {duplicate_count} duplicate rows in the DataFrame.\")\n",
    "else:\n",
    "    print(\"✅ No duplicate rows found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fdb46",
   "metadata": {},
   "source": [
    "To print the original + duplicates in grassland_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will include both the original and its duplicates\n",
    "duplicates_all = grassland_merged_df[grassland_merged_df.duplicated(keep=False)]\n",
    "print(duplicates_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e469c",
   "metadata": {},
   "source": [
    "Now we can drop the duplicates and keep the first instance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "13d1879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df = grassland_merged_df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "515c6079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Remaining duplicates: {grassland_merged_df.duplicated().sum()}\")  # Should be 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef56a0",
   "metadata": {},
   "source": [
    "Now to analyse the data types of the columns in grassland_merged_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f5adf5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Admin_Unit_Code                        object\n",
       "Plot_Name                              object\n",
       "Location_Type                          object\n",
       "Year                                    int64\n",
       "Date                           datetime64[ns]\n",
       "Start_Time                             object\n",
       "End_Time                               object\n",
       "Observer                               object\n",
       "Visit                                   int64\n",
       "Interval_Length                        object\n",
       "ID_Method                              object\n",
       "Distance                               object\n",
       "Flyover_Observed                         bool\n",
       "Sex                                    object\n",
       "Common_Name                            object\n",
       "Scientific_Name                        object\n",
       "AcceptedTSN                            object\n",
       "TaxonCode                              object\n",
       "AOU_Code                               object\n",
       "PIF_Watchlist_Status                     bool\n",
       "Regional_Stewardship_Status              bool\n",
       "Temperature                           float64\n",
       "Humidity                              float64\n",
       "Sky                                    object\n",
       "Wind                                   object\n",
       "Disturbance                            object\n",
       "Previously_Obs                           bool\n",
       "Initial_Three_Min_Cnt                    bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grassland_merged_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8314494f",
   "metadata": {},
   "source": [
    "Now the Start_Time and End_Time are in object format (string) which needs to be converted and only Time should be present :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "465ba1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df['Start_Time'] = pd.to_datetime(grassland_merged_df['Start_Time'], format='%H:%M:%S', errors='coerce').dt.time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a3c5f",
   "metadata": {},
   "source": [
    "To confirm if the Start_Time is of correct class datetime.time :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "55d4cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'datetime.time'>], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grassland_merged_df['Start_Time'].apply(type).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9cb705",
   "metadata": {},
   "source": [
    "Now check for End_Time and do the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d7d9580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'datetime.time'>], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_merged_df['End_Time'] = pd.to_datetime(forest_merged_df['End_Time'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "forest_merged_df['Start_Time'].apply(type).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d1282fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values are False:\n"
     ]
    }
   ],
   "source": [
    "only_false = grassland_merged_df['Previously_Obs'].eq(False).all()\n",
    "print(\"All values are False:\" if only_false else \"There are True or missing values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e87ee122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "print(grassland_merged_df['Previously_Obs'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a9c332",
   "metadata": {},
   "source": [
    "We can drop the column 'Previously_Obs' as all values are 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4538ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_merged_df.drop(columns=['Previously_Obs'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83e4c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Admin_Unit_Code', 'Plot_Name', 'Location_Type', 'Year', 'Date',\n",
      "       'Start_Time', 'End_Time', 'Observer', 'Visit', 'Interval_Length',\n",
      "       'ID_Method', 'Distance', 'Flyover_Observed', 'Sex', 'Common_Name',\n",
      "       'Scientific_Name', 'AcceptedTSN', 'TaxonCode', 'AOU_Code',\n",
      "       'PIF_Watchlist_Status', 'Regional_Stewardship_Status', 'Temperature',\n",
      "       'Humidity', 'Sky', 'Wind', 'Disturbance', 'Initial_Three_Min_Cnt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(grassland_merged_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e5ab1fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Admin_Unit_Code', 'Site_Name', 'Plot_Name', 'Location_Type', 'Year',\n",
      "       'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
      "       'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex',\n",
      "       'Common_Name', 'Scientific_Name', 'AcceptedTSN', 'NPSTaxonCode',\n",
      "       'AOU_Code', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status',\n",
      "       'Temperature', 'Humidity', 'Sky', 'Wind', 'Disturbance',\n",
      "       'Initial_Three_Min_Cnt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(forest_merged_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dba454",
   "metadata": {},
   "source": [
    "Rename NPSTaxonCode in forest_merged_df as TaxonCode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "826bc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_merged_df.rename(columns={'NPSTaxonCode': 'TaxonCode'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbf558",
   "metadata": {},
   "source": [
    "Now creat df grassland_plot_details and forest_plot_details which stores the unique set of columns 'Admin_Unit_Code', 'Location_Type' for a particular plot_name. In case of forst_plot_details column 'Site_Name' is also added. Concatenate both to get one plot_details df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "84aef544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Admin_Unit_Code Location_Type Site_Name\n",
      "Plot_Name                                        \n",
      "ANTI-0054            ANTI     Grassland       NaN\n",
      "ANTI-0028            ANTI     Grassland       NaN\n",
      "ANTI-0027            ANTI     Grassland       NaN\n",
      "ANTI-0018            ANTI     Grassland       NaN\n",
      "ANTI-0105            ANTI     Grassland       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select relevant columns from both DataFrames, adding 'Site_Name' only where available\n",
    "grassland_plot_details = grassland_merged_df[['Plot_Name', 'Admin_Unit_Code', 'Location_Type']].copy()\n",
    "grassland_plot_details['Site_Name'] = pd.NA  # Add missing column with nulls\n",
    "\n",
    "forest_plot_details = forest_merged_df[['Plot_Name', 'Admin_Unit_Code', 'Location_Type', 'Site_Name']].copy()\n",
    "\n",
    "# Concatenate the two\n",
    "plot_details = pd.concat([grassland_plot_details, forest_plot_details], ignore_index=True)\n",
    "\n",
    "# Drop duplicates to ensure one row per unique Plot_Name (keeping first occurrence)\n",
    "plot_details = plot_details.drop_duplicates(subset=['Plot_Name'])\n",
    "\n",
    "# Set 'Plot_Name' as index\n",
    "plot_details.set_index('Plot_Name', inplace=True)\n",
    "\n",
    "# Final Plot_Details table\n",
    "Plot_Details = plot_details\n",
    "\n",
    "# Display result (optional)\n",
    "print(Plot_Details.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9f34713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609, 3)\n"
     ]
    }
   ],
   "source": [
    "print(plot_details.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a973d",
   "metadata": {},
   "source": [
    "Create species_details df with the columns 'Common_Name', 'Scientific_Name', 'AcceptedTSN', 'TaxonCode',\n",
    "    'AOU_Code', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status' as all these values are unique for a particular Common Name. Also the index can be the Common_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402cf66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns we need for Species_Details\n",
    "species_columns = [\n",
    "    'Common_Name', 'Scientific_Name', 'AcceptedTSN', 'TaxonCode',\n",
    "    'AOU_Code', 'PIF_Watchlist_Status', 'Regional_Stewardship_Status'\n",
    "]\n",
    "\n",
    "# Extract relevant columns from both dataframes\n",
    "grassland_species = grassland_merged_df[species_columns].copy()\n",
    "forest_species = forest_merged_df[species_columns].copy()\n",
    "\n",
    "# Concatenate both species DataFrames\n",
    "species_combined = pd.concat([grassland_species, forest_species], ignore_index=True)\n",
    "\n",
    "# Drop duplicates to ensure unique rows per Common_Name\n",
    "species_details = species_combined.drop_duplicates(subset='Common_Name')\n",
    "\n",
    "# Set Common_Name as the index\n",
    "species_details.set_index('Common_Name', inplace=True)\n",
    "\n",
    "# Display the resulting Species_Details table\n",
    "print(species_details.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbd723",
   "metadata": {},
   "source": [
    "Now we create 2 dfs : forest_bird_observations and grassland_bird_observations with 'Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer','Visit', 'Interval_Length', 'ID_Method', 'Distance','Flyover_Observed', 'Sex', 'Common_Name', 'Temperature', 'Humidity', 'Sky', 'Wind','Disturbance', 'Initial_Three_Min_Cnt'columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a124e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the required columns\n",
    "observation_columns = [\n",
    "    'Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
    "    'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex',\n",
    "    'Common_Name', 'Temperature', 'Humidity', 'Sky', 'Wind',\n",
    "    'Disturbance', 'Initial_Three_Min_Cnt'\n",
    "]\n",
    "\n",
    "# Create forest bird observations DataFrame\n",
    "forest_bird_observations = forest_merged_df[observation_columns].copy()\n",
    "\n",
    "# Create grassland bird observations DataFrame\n",
    "grassland_bird_observations = grassland_merged_df[observation_columns].copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9164f4",
   "metadata": {},
   "source": [
    "Now need to move data from 4 dfs namely: forest_bird_observations, grassland_bird_observations, Plot_details and species_details into 4 tables in SQL Workbench . The Plot_Name will be the primary key in Plot_details table and 'Common_Name' will be the primary key in species_details table and these 2 columns will be the foreign keys in forest_bird_observations and grassland_bird_observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a5a0f",
   "metadata": {},
   "source": [
    "pip install mysql-connector-python sqlalchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d21275",
   "metadata": {},
   "source": [
    "Create lookup tables to avoid long strings in columns 'Sky', 'Wind','Disturbance' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9dc90655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_lookup_and_merge(df1, df2, column_name):\n",
    "    # Get unique non-null values from both DataFrames\n",
    "    combined_unique_values = pd.Series(\n",
    "        pd.concat([df1[column_name], df2[column_name]])\n",
    "        .dropna()\n",
    "        .unique()\n",
    "    ).sort_values().reset_index(drop=True)\n",
    "    \n",
    "    # Create a lookup table\n",
    "    lookup_df = pd.DataFrame({\n",
    "        f'{column_name}_Code': range(1, len(combined_unique_values) + 1),\n",
    "        column_name: combined_unique_values\n",
    "    })\n",
    "\n",
    "    # Merge the lookup into both DataFrames and drop original column\n",
    "    df1 = df1.merge(lookup_df, on=column_name, how='left').drop(columns=[column_name])\n",
    "    df2 = df2.merge(lookup_df, on=column_name, how='left').drop(columns=[column_name])\n",
    "    \n",
    "    return df1, df2, lookup_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sky\n",
    "forest_bird_observations, grassland_bird_observations, sky_lookup = create_combined_lookup_and_merge(\n",
    "    forest_bird_observations, grassland_bird_observations, 'Sky')\n",
    "\n",
    "# Wind\n",
    "forest_bird_observations, grassland_bird_observations, wind_lookup = create_combined_lookup_and_merge(\n",
    "    forest_bird_observations, grassland_bird_observations, 'Wind')\n",
    "\n",
    "# Disturbance\n",
    "forest_bird_observations, grassland_bird_observations, disturbance_lookup = create_combined_lookup_and_merge(\n",
    "    forest_bird_observations, grassland_bird_observations, 'Disturbance')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a2d21dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest columns: Index(['Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
      "       'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex',\n",
      "       'Common_Name', 'Temperature', 'Humidity', 'Initial_Three_Min_Cnt',\n",
      "       'Sky_Code', 'Wind_Code', 'Disturbance_Code'],\n",
      "      dtype='object')\n",
      "Grassland columns: Index(['Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
      "       'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex',\n",
      "       'Common_Name', 'Temperature', 'Humidity', 'Initial_Three_Min_Cnt',\n",
      "       'Sky_Code', 'Wind_Code', 'Disturbance_Code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Forest columns:\", forest_bird_observations.columns)\n",
    "print(\"Grassland columns:\", grassland_bird_observations.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3705c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (forest_bird_observations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (grassland_bird_observations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732b0b46",
   "metadata": {},
   "source": [
    "To check and clean Interval_Length column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c3ce4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values end with 'min': True\n"
     ]
    }
   ],
   "source": [
    "all_end_with_min = forest_bird_observations['Interval_Length'].astype(str).str.endswith('min').all()\n",
    "print(\"All values end with 'min':\", all_end_with_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e6575b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0-2.5 min' '2.5 - 5 min' '5 - 7.5 min' '7.5 - 10 min']\n"
     ]
    }
   ],
   "source": [
    "print(forest_bird_observations['Interval_Length'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "72fd648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0-2.5 min' '7.5 - 10 min' '2.5 - 5 min' '5 - 7.5 min']\n"
     ]
    }
   ],
   "source": [
    "print(grassland_bird_observations['Interval_Length'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdd63c0",
   "metadata": {},
   "source": [
    " Add Interval_Start, Interval_End, and Interval_Avg to forest_bird_observations and grassland_bird_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "34e0c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and extract interval values\n",
    "interval_split = forest_bird_observations['Interval_Length'].astype(str).str.extract(\n",
    "    r'(?P<Interval_Start>[\\d\\.]+)\\s*-\\s*(?P<Interval_End>[\\d\\.]+)'\n",
    ")\n",
    "\n",
    "# Convert to float\n",
    "interval_split['Interval_Start'] = interval_split['Interval_Start'].astype(float)\n",
    "interval_split['Interval_End'] = interval_split['Interval_End'].astype(float)\n",
    "\n",
    "# Calculate average\n",
    "interval_split['Interval_Avg'] = (interval_split['Interval_Start'] + interval_split['Interval_End']) / 2\n",
    "\n",
    "# Merge into the original DataFrame\n",
    "forest_bird_observations = pd.concat([forest_bird_observations, interval_split], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "55058ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and extract interval values\n",
    "interval_split = grassland_bird_observations['Interval_Length'].astype(str).str.extract(\n",
    "    r'(?P<Interval_Start>[\\d\\.]+)\\s*-\\s*(?P<Interval_End>[\\d\\.]+)'\n",
    ")\n",
    "\n",
    "# Convert to float\n",
    "interval_split['Interval_Start'] = interval_split['Interval_Start'].astype(float)\n",
    "interval_split['Interval_End'] = interval_split['Interval_End'].astype(float)\n",
    "\n",
    "# Calculate average\n",
    "interval_split['Interval_Avg'] = (interval_split['Interval_Start'] + interval_split['Interval_End']) / 2\n",
    "\n",
    "# Merge into the original DataFrame\n",
    "grassland_bird_observations = pd.concat([grassland_bird_observations, interval_split], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfbdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grassland_bird_observations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce67f37",
   "metadata": {},
   "source": [
    "Distance can also be cleaned and processed. First we extract unique distance categories from both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eabb2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_distance_categories(*dfs):\n",
    "    unique_distances = set()\n",
    "    for df in dfs:\n",
    "        unique_distances.update(df['Distance'].dropna().unique())\n",
    "    return sorted(unique_distances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9236a6",
   "metadata": {},
   "source": [
    "Then create a lookup table with the parsed information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eae33847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance_Code</th>\n",
       "      <th>Distance_Start</th>\n",
       "      <th>Distance_End</th>\n",
       "      <th>Distance_Category</th>\n",
       "      <th>Distance_Raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50-100m</td>\n",
       "      <td>50 - 100 Meters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>&lt;= 50m</td>\n",
       "      <td>&lt;= 50 Meters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Distance_Code  Distance_Start  Distance_End Distance_Category  \\\n",
       "0              0            50.0         100.0           50-100m   \n",
       "1              1             0.0          50.0            <= 50m   \n",
       "\n",
       "      Distance_Raw  \n",
       "0  50 - 100 Meters  \n",
       "1     <= 50 Meters  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def parse_distance(distance_str):\n",
    "    if pd.isnull(distance_str):\n",
    "        return (np.nan, np.nan, 'Unknown')\n",
    "    \n",
    "    s = distance_str.strip()\n",
    "    \n",
    "    if \"<=\" in s:\n",
    "        val = float(s.replace(\"<= \", \"\").replace(\"Meters\", \"\").strip())\n",
    "        label = f\"<= {int(val)}m\"\n",
    "        return (0, val, label)\n",
    "    elif \" - \" in s:\n",
    "        parts = s.replace(\"Meters\", \"\").strip().split(\" - \")\n",
    "        start = float(parts[0])\n",
    "        end = float(parts[1])\n",
    "        label = f\"{int(start)}-{int(end)}m\"\n",
    "        return (start, end, label)\n",
    "    elif \">=\" in s:\n",
    "        val = float(s.replace(\">= \", \"\").replace(\"Meters\", \"\").strip())\n",
    "        label = f\">= {int(val)}m\"\n",
    "        return (val, np.nan, label)\n",
    "    elif \">\" in s:\n",
    "        val = float(s.replace(\"> \", \"\").replace(\"Meters\", \"\").strip())\n",
    "        label = f\"> {int(val)}m\"\n",
    "        return (val, np.nan, label)\n",
    "    else:\n",
    "        return (np.nan, np.nan, 'Other')\n",
    "\n",
    "# Get unique categories from both dfs\n",
    "unique_distances = get_unique_distance_categories(forest_bird_observations, grassland_bird_observations)\n",
    "\n",
    "# Parse and build lookup data\n",
    "lookup_data = [parse_distance(d) for d in unique_distances]\n",
    "\n",
    "# Create lookup DataFrame\n",
    "distance_lookup_df = pd.DataFrame(lookup_data, columns=['Distance_Start', 'Distance_End', 'Distance_Category'])\n",
    "distance_lookup_df['Distance_Raw'] = unique_distances  # original strings for reference\n",
    "\n",
    "# Assign a numeric code as primary key\n",
    "distance_lookup_df.reset_index(inplace=True)\n",
    "distance_lookup_df.rename(columns={'index': 'Distance_Code'}, inplace=True)\n",
    "\n",
    "distance_lookup_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eda94f",
   "metadata": {},
   "source": [
    "Map Distance strings in bird observations to this lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "326a2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Distance to Distance_Code using the raw string\n",
    "mapping_dict = dict(zip(distance_lookup_df['Distance_Raw'], distance_lookup_df['Distance_Code']))\n",
    "\n",
    "# Apply to both dataframes\n",
    "forest_bird_observations['Distance_Code'] = forest_bird_observations['Distance'].map(mapping_dict)\n",
    "grassland_bird_observations['Distance_Code'] = grassland_bird_observations['Distance'].map(mapping_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f6ef0",
   "metadata": {},
   "source": [
    "Connection to SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d066f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define your MySQL connection string\n",
    "username = 'root'\n",
    "password = 'Raji'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database = 'birdobservation_db'\n",
    "\n",
    "# Create connection engine\n",
    "engine = create_engine(f'mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c20435",
   "metadata": {},
   "source": [
    "Uploading Lookup Tables First:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_details.to_sql('Plot_details', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39b96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plot_details['Plot_Name'].isnull().sum())\n",
    "print(plot_details[plot_details['Plot_Name'].isnull()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5794ebb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admin_Unit_Code</th>\n",
       "      <th>Location_Type</th>\n",
       "      <th>Site_Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plot_Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANTI-0054</th>\n",
       "      <td>ANTI</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANTI-0028</th>\n",
       "      <td>ANTI</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANTI-0027</th>\n",
       "      <td>ANTI</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANTI-0018</th>\n",
       "      <td>ANTI</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANTI-0105</th>\n",
       "      <td>ANTI</td>\n",
       "      <td>Grassland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Admin_Unit_Code Location_Type Site_Name\n",
       "Plot_Name                                        \n",
       "ANTI-0054            ANTI     Grassland       NaN\n",
       "ANTI-0028            ANTI     Grassland       NaN\n",
       "ANTI-0027            ANTI     Grassland       NaN\n",
       "ANTI-0018            ANTI     Grassland       NaN\n",
       "ANTI-0105            ANTI     Grassland       NaN"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "793bf47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_details = plot_details.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bc8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_details.to_sql('Plot_details', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3d828855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common_Name</th>\n",
       "      <th>Scientific_Name</th>\n",
       "      <th>AcceptedTSN</th>\n",
       "      <th>TaxonCode</th>\n",
       "      <th>AOU_Code</th>\n",
       "      <th>PIF_Watchlist_Status</th>\n",
       "      <th>Regional_Stewardship_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chipping Sparrow</td>\n",
       "      <td>Spizella passerina</td>\n",
       "      <td>179435.0</td>\n",
       "      <td>84781.0</td>\n",
       "      <td>CHSP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eastern Bluebird</td>\n",
       "      <td>Sialia sialis</td>\n",
       "      <td>179801.0</td>\n",
       "      <td>87184.0</td>\n",
       "      <td>EABL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grasshopper Sparrow</td>\n",
       "      <td>Ammodramus savannarum</td>\n",
       "      <td>179333.0</td>\n",
       "      <td>83867.0</td>\n",
       "      <td>GRSP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Field Sparrow</td>\n",
       "      <td>Spizella pusilla</td>\n",
       "      <td>179443.0</td>\n",
       "      <td>84790.0</td>\n",
       "      <td>FISP</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Crow</td>\n",
       "      <td>Corvus brachyrhynchos</td>\n",
       "      <td>179731.0</td>\n",
       "      <td>87106.0</td>\n",
       "      <td>AMCR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Unidentified Woodpecker</td>\n",
       "      <td>Picadae</td>\n",
       "      <td>847323.0</td>\n",
       "      <td>816311</td>\n",
       "      <td>UNWO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Yellow-rumped Warbler</td>\n",
       "      <td>Setophaga coronata</td>\n",
       "      <td>950046.0</td>\n",
       "      <td>773779</td>\n",
       "      <td>YRWA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Nashville Warbler</td>\n",
       "      <td>Oreothlypis ruficapilla</td>\n",
       "      <td>950106.0</td>\n",
       "      <td>773768</td>\n",
       "      <td>NAWA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Tennessee Warbler</td>\n",
       "      <td>Oreothlypis peregrina</td>\n",
       "      <td>950097.0</td>\n",
       "      <td>773770</td>\n",
       "      <td>TEWA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Red-headed Woodpecker</td>\n",
       "      <td>Melanerpes erythrocephalus</td>\n",
       "      <td>178186.0</td>\n",
       "      <td>84855</td>\n",
       "      <td>RHWO</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Common_Name             Scientific_Name AcceptedTSN  \\\n",
       "0           Chipping Sparrow          Spizella passerina    179435.0   \n",
       "1           Eastern Bluebird               Sialia sialis    179801.0   \n",
       "2        Grasshopper Sparrow       Ammodramus savannarum    179333.0   \n",
       "3              Field Sparrow            Spizella pusilla    179443.0   \n",
       "4              American Crow       Corvus brachyrhynchos    179731.0   \n",
       "..                       ...                         ...         ...   \n",
       "121  Unidentified Woodpecker                     Picadae    847323.0   \n",
       "122    Yellow-rumped Warbler          Setophaga coronata    950046.0   \n",
       "123        Nashville Warbler     Oreothlypis ruficapilla    950106.0   \n",
       "124        Tennessee Warbler       Oreothlypis peregrina    950097.0   \n",
       "125    Red-headed Woodpecker  Melanerpes erythrocephalus    178186.0   \n",
       "\n",
       "    TaxonCode AOU_Code  PIF_Watchlist_Status  Regional_Stewardship_Status  \n",
       "0     84781.0     CHSP                 False                        False  \n",
       "1     87184.0     EABL                 False                        False  \n",
       "2     83867.0     GRSP                 False                        False  \n",
       "3     84790.0     FISP                 False                         True  \n",
       "4     87106.0     AMCR                 False                        False  \n",
       "..        ...      ...                   ...                          ...  \n",
       "121    816311     UNWO                 False                        False  \n",
       "122    773779     YRWA                 False                        False  \n",
       "123    773768     NAWA                 False                        False  \n",
       "124    773770     TEWA                 False                        False  \n",
       "125     84855     RHWO                  True                        False  \n",
       "\n",
       "[126 rows x 7 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_details.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43227df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_details.to_sql('Species_details', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "87c97fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_details = species_details.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2452396",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_details.to_sql('Species_details', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "43a4727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_lookup = sky_lookup.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "93800a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['level_0', 'index', 'Sky_Code', 'Sky'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sky_lookup.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a2d7d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_lookup_cleaned = sky_lookup[['Sky_Code', 'Sky']].rename(columns={'Sky': 'Sky_Description'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb43523",
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_lookup_cleaned.to_sql('Sky_Lookup', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For wind\n",
    "wind_lookup_cleaned = wind_lookup[['Wind_Code', 'Wind']].rename(columns={'Wind': 'Wind_Description'})\n",
    "wind_lookup_cleaned.to_sql('Wind_Lookup', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# For disturbance\n",
    "disturbance_lookup_cleaned = disturbance_lookup[['Disturbance_Code', 'Disturbance']].rename(columns={'Disturbance': 'Disturbance_Description'})\n",
    "disturbance_lookup_cleaned.to_sql('Disturbance_Lookup', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "53fe3e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Distance_Code', 'Distance_Start', 'Distance_End', 'Distance_Category',\n",
      "       'Distance_Raw'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(distance_lookup_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "90befcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_lookup_cleaned = distance_lookup_df[[\n",
    "    'Distance_Code', 'Distance_Raw', 'Distance_Start', 'Distance_End', 'Distance_Category'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4c544692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_1332\\1366051435.py:1: UserWarning: The provided table name 'Distance_Lookup' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  distance_lookup_cleaned.to_sql('Distance_Lookup', con=engine, if_exists='append', index=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_lookup_cleaned.to_sql('Distance_Lookup', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "138d57b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
      "       'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex',\n",
      "       'Common_Name', 'Temperature', 'Humidity', 'Initial_Three_Min_Cnt',\n",
      "       'Sky_Code', 'Wind_Code', 'Disturbance_Code', 'Interval_Start',\n",
      "       'Interval_End', 'Interval_Avg', 'Distance_Code'],\n",
      "      dtype='object')\n",
      "Index(['Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
      "       'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex',\n",
      "       'Common_Name', 'Temperature', 'Humidity', 'Initial_Three_Min_Cnt',\n",
      "       'Sky_Code', 'Wind_Code', 'Disturbance_Code', 'Interval_Start',\n",
      "       'Interval_End', 'Interval_Avg', 'Distance_Code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(grassland_bird_observations.columns)\n",
    "print(forest_bird_observations.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "832d843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_bird_observations = grassland_bird_observations.drop(columns=['index', 'level_0', 'Observation_ID'], errors='ignore')\n",
    "forest_bird_observations = forest_bird_observations.drop(columns=['index', 'level_0', 'Observation_ID'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668369d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grassland_bird_observations.columns)\n",
    "print(forest_bird_observations.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "13b6def2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot_Name                 object\n",
      "Date                      object\n",
      "Start_Time                object\n",
      "End_Time                  object\n",
      "Observer                  object\n",
      "Visit                      int64\n",
      "Interval_Length           object\n",
      "ID_Method                 object\n",
      "Distance                  object\n",
      "Flyover_Observed            bool\n",
      "Sex                       object\n",
      "Common_Name               object\n",
      "Temperature              float64\n",
      "Humidity                 float64\n",
      "Initial_Three_Min_Cnt       bool\n",
      "Sky_Code                   int64\n",
      "Wind_Code                  int64\n",
      "Disturbance_Code           int64\n",
      "Interval_Start           float64\n",
      "Interval_End             float64\n",
      "Interval_Avg             float64\n",
      "Distance_Code              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(grassland_bird_observations.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f5191",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_bird_observations['Date'] = pd.to_datetime(grassland_bird_observations['Date']).dt.date\n",
    "grassland_bird_observations['Start_Time'] = pd.to_datetime(grassland_bird_observations['Start_Time']).dt.time\n",
    "grassland_bird_observations['End_Time'] = pd.to_datetime(grassland_bird_observations['End_Time']).dt.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cd622a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "print(type(grassland_bird_observations['Date'].iloc[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8df6851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
      "       'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex',\n",
      "       'Common_Name', 'Temperature', 'Humidity', 'Initial_Three_Min_Cnt',\n",
      "       'Sky_Code', 'Wind_Code', 'Disturbance_Code', 'Interval_Start',\n",
      "       'Interval_End', 'Interval_Avg', 'Distance_Code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(grassland_bird_observations.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fc4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_bird_observations.to_sql('grassland_bird_observations', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "89782670",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_bird_observations.rename(columns={\n",
    "    'Interval_Start': 'Interval_Length_Start',\n",
    "    'Interval_End': 'Interval_Length_End',\n",
    "    'Interval_Avg': 'Interval_Length_Avg'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e0f641d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grassland_bird_observations.drop(columns=['Interval_Length', 'Distance'], inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6f4be933",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_columns = [\n",
    "    'Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
    "    'Interval_Length_Start', 'Interval_Length_End', 'Interval_Length_Avg',\n",
    "    'ID_Method', 'Distance_Code', 'Flyover_Observed', 'Sex', 'Common_Name',\n",
    "    'Temperature', 'Humidity', 'Sky_Code', 'Wind_Code',\n",
    "    'Disturbance_Code', 'Initial_Three_Min_Cnt'\n",
    "]\n",
    "\n",
    "grassland_bird_observations = grassland_bird_observations[expected_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3110bf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6826"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grassland_bird_observations.to_sql('grassland_bird_observations', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bf5573d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Plot_Name', 'Date', 'Start_Time', 'End_Time', 'Observer', 'Visit',\n",
      "       'Interval_Length', 'ID_Method', 'Distance', 'Flyover_Observed', 'Sex',\n",
      "       'Common_Name', 'Temperature', 'Humidity', 'Initial_Three_Min_Cnt',\n",
      "       'Sky_Code', 'Wind_Code', 'Disturbance_Code', 'Interval_Start',\n",
      "       'Interval_End', 'Interval_Avg', 'Distance_Code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(forest_bird_observations.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c7f3ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_bird_observations = forest_bird_observations.rename(columns={\n",
    "    'Interval_Start': 'Interval_Length_Start',\n",
    "    'Interval_End': 'Interval_Length_End',\n",
    "    'Interval_Avg': 'Interval_Length_Avg',\n",
    "    'Distance_Code': 'Distance_Code'  # same, just ensure exists\n",
    "})\n",
    "\n",
    "# Drop columns not in SQL table if needed\n",
    "forest_bird_observations = forest_bird_observations.drop(columns=['Interval_Length', 'Distance'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b77b5746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8542"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_bird_observations.to_sql('forest_bird_observations', con=engine, if_exists='append', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
